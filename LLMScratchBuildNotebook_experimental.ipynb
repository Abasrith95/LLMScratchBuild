{"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"afc61cb04e44491b8109012ce0d25ed6":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_2b94b5cceba44eea903226973aad5aff","IPY_MODEL_2e47b5ec5ff547e0bd940641129b78f6","IPY_MODEL_200cd12eda4b40cdab0c98e121967b31"],"layout":"IPY_MODEL_7313e5d8da8e429e922df82792c6e25a"}},"2b94b5cceba44eea903226973aad5aff":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfeef812a9164b158f09ab334bbd878b","placeholder":"​","style":"IPY_MODEL_676b751da39f4a40a048cd5dc86be24f","value":"Loading dataset shards: 100%"}},"2e47b5ec5ff547e0bd940641129b78f6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d8c3f121206043f5bf5b0a1b1d1cc721","max":80,"min":0,"orientation":"horizontal","style":"IPY_MODEL_1b8caf731295490da12b83a4630a8fd3","value":80}},"200cd12eda4b40cdab0c98e121967b31":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_90c5588bc88d4adcbc9300eeca828db6","placeholder":"​","style":"IPY_MODEL_30b88cb7050b430baaeab9ec5ed09477","value":" 80/80 [01:09&lt;00:00,  1.32it/s]"}},"7313e5d8da8e429e922df82792c6e25a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cfeef812a9164b158f09ab334bbd878b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"676b751da39f4a40a048cd5dc86be24f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d8c3f121206043f5bf5b0a1b1d1cc721":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1b8caf731295490da12b83a4630a8fd3":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"90c5588bc88d4adcbc9300eeca828db6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"30b88cb7050b430baaeab9ec5ed09477":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30683,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"! pip install datasets\nfrom datasets import load_dataset\ndataset = load_dataset(\"Skylion007/openwebtext\", split=\"train\")\n","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":781,"referenced_widgets":["afc61cb04e44491b8109012ce0d25ed6","2b94b5cceba44eea903226973aad5aff","2e47b5ec5ff547e0bd940641129b78f6","200cd12eda4b40cdab0c98e121967b31","7313e5d8da8e429e922df82792c6e25a","cfeef812a9164b158f09ab334bbd878b","676b751da39f4a40a048cd5dc86be24f","d8c3f121206043f5bf5b0a1b1d1cc721","1b8caf731295490da12b83a4630a8fd3","90c5588bc88d4adcbc9300eeca828db6","30b88cb7050b430baaeab9ec5ed09477"]},"id":"eG4WIBCdrok_","outputId":"145b79dd-e0fb-4106-a28c-205d473d661b","execution":{"iopub.status.busy":"2024-04-15T06:37:15.474361Z","iopub.execute_input":"2024-04-15T06:37:15.474763Z","iopub.status.idle":"2024-04-15T06:37:52.698389Z","shell.execute_reply.started":"2024-04-15T06:37:15.474719Z","shell.execute_reply":"2024-04-15T06:37:52.697569Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.13.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=12.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (15.0.2)\nRequirement already satisfied: pyarrow-hotfix in /opt/conda/lib/python3.10/site-packages (from datasets) (0.6)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.2.0,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets) (2024.2.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub>=0.19.4 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.22.2)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for Skylion007/openwebtext contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/Skylion007/openwebtext\nYou can avoid this message in future by passing the argument `trust_remote_code=True`.\nPassing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading dataset shards:   0%|          | 0/80 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b3015c9b34184d0193df350ea881fc9d"}},"metadata":{}}]},{"cell_type":"code","source":"! pip install tiktoken\nimport tiktoken\nimport torch\nfrom torch.utils.data import Dataset, DataLoader, random_split\nfrom tiktoken import get_encoding\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"726Ay5qZ_RPo","outputId":"bafbb796-3e09-4a7c-fc56-fb34720866b8","execution":{"iopub.status.busy":"2024-04-15T06:38:36.055141Z","iopub.execute_input":"2024-04-15T06:38:36.056347Z","iopub.status.idle":"2024-04-15T06:38:48.214728Z","shell.execute_reply.started":"2024-04-15T06:38:36.056310Z","shell.execute_reply":"2024-04-15T06:38:48.213466Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tiktoken in /opt/conda/lib/python3.10/site-packages (0.6.0)\nRequirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2023.12.25)\nRequirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken) (2.31.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n","output_type":"stream"}]},{"cell_type":"code","source":"# class TextDataset(torch.utils.data.Dataset):\n#     def __init__(self, texts, tokenizer):\n#         self.texts = texts\n#         self.tokenizer = tokenizer\n#         self.block_size = 32\n\n#     def __len__(self):\n#         return len(self.texts)\n\n#     def __getitem__(self, idx):\n#         data = \" \".join(self.texts)\n#         self.encoded_text = self.tokenizer.encode(data) # tokenizing in batches\n#         x = self.encoded_text[idx:idx+self.block_size]\n#         y = self.encoded_text[idx+1:idx+self.block_size+1]\n#         return x, y\n","metadata":{"id":"rgN1lzHwGLsI","execution":{"iopub.status.busy":"2024-04-15T06:08:40.561512Z","iopub.execute_input":"2024-04-15T06:08:40.562258Z","iopub.status.idle":"2024-04-15T06:08:40.566318Z","shell.execute_reply.started":"2024-04-15T06:08:40.562225Z","shell.execute_reply":"2024-04-15T06:08:40.565406Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(len(dataset))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HSTBD2beXNTv","outputId":"d21b8a11-6d0a-4919-ec5b-0775f018b3fa","execution":{"iopub.status.busy":"2024-04-15T06:24:32.476998Z","iopub.execute_input":"2024-04-15T06:24:32.478265Z","iopub.status.idle":"2024-04-15T06:24:32.483143Z","shell.execute_reply.started":"2024-04-15T06:24:32.478229Z","shell.execute_reply":"2024-04-15T06:24:32.482121Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"8013769\n","output_type":"stream"}]},{"cell_type":"code","source":"# print(len(dataset))\n# print(dataset[0])\n# print(dataset[1])\n# print(dataset)\n\n# enc = tiktoken.get_encoding('gpt2')\n# vocab_size = enc.n_vocab\n\n# dataset_subset =  dataset.select(range(100000))\n# tokenizer = get_encoding('gpt2')\n# texts = [text['text'] for text in dataset_subset]\n\n# # Initialize dataset\n# text_dataset = TextDataset(texts, tokenizer)\n\n# # Split dataset into training and validation sets\n# train_size = int(0.9 * len(text_dataset))\n# val_size = len(text_dataset) - train_size\n# train_dataset, val_dataset = random_split(text_dataset, [train_size, val_size])\n\n# # DataLoader\n# batch_size = 16\n# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n# val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CFMpgFeZGTG2","outputId":"99e43a99-5ea4-4122-b645-a86c449c9518","execution":{"iopub.status.busy":"2024-04-15T06:08:43.975959Z","iopub.execute_input":"2024-04-15T06:08:43.976814Z","iopub.status.idle":"2024-04-15T06:08:43.981071Z","shell.execute_reply.started":"2024-04-15T06:08:43.976780Z","shell.execute_reply":"2024-04-15T06:08:43.980162Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"enc = tiktoken.get_encoding('gpt2')\nvocab_size = enc.n_vocab\n\n# print(len(dataset))\n# print(dataset[0])\n# print(dataset[1])\n# print(dataset)\n\ndataset_subset =  dataset.select(range(2000000))\ndataset_subset = dataset_subset['text']\nn = int(0.8*len(dataset_subset)) # first 90% will be train, rest val\ntrain_data = dataset_subset[:n]\nval_data = dataset_subset[n:]","metadata":{"execution":{"iopub.status.busy":"2024-04-15T06:39:52.636272Z","iopub.execute_input":"2024-04-15T06:39:52.637081Z","iopub.status.idle":"2024-04-15T06:40:08.401530Z","shell.execute_reply.started":"2024-04-15T06:39:52.637048Z","shell.execute_reply":"2024-04-15T06:40:08.400613Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"\n\n\n# hyperparameters\nbatch_size = 16 # how many independent sequences will we process in parallel? #16\nblock_size = 32 # what is the maximum context length for predictions? #32\nmax_iters = 5000\neval_interval = 100\nlearning_rate = 1e-3\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\neval_iters = 200\nn_embd = 64\nn_head = 4\nn_layer = 4\ndropout = 0.0\n# ------------\n\nenc = tiktoken.get_encoding('gpt2')\n\n# data loading\ndef get_batch(split):\n    data = train_data if split == 'train' else val_data\n    # print(len(data))\n    # print(batch_size*block_size)\n    random_int = torch.randint(len(data)- batch_size*block_size, (1,))\n    start_index = int(random_int.item())\n\n    data = train_data if split == 'train' else val_data\n    sampled_elements = data[start_index:start_index + 4]\n    combined_text = \" \".join(sampled_elements)\n\n    data = torch.tensor(enc.encode(combined_text), dtype=torch.long)\n\n    ix = torch.randint(len(data) - block_size, (batch_size,)) #generate random number in the shape of block size\n    x = torch.stack([data[i:i+block_size] for i in ix])\n    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n    x, y = x.to(device), y.to(device)\n\n    # print(\"printing once\")\n    # print(x)\n    # print(y)\n    return x, y\n\n@torch.no_grad()\ndef estimate_loss():\n    out = {}\n    model.eval()\n    for split in ['train', 'val']:\n        losses = torch.zeros(eval_iters)\n        for k in range(eval_iters):\n            X, Y = get_batch(split)\n            logits, loss = model(X, Y)\n            losses[k] = loss.item()\n        out[split] = losses.mean()\n    model.train()\n    return out\n\nclass Head(nn.Module):\n    \"\"\" one head of self-attention \"\"\"\n\n    def __init__(self, head_size):\n        super().__init__()\n        self.key = nn.Linear(n_embd, head_size, bias=False)\n        self.query = nn.Linear(n_embd, head_size, bias=False)\n        self.value = nn.Linear(n_embd, head_size, bias=False)\n        self.register_buffer('tril', torch.tril(torch.ones(block_size, block_size)))\n\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        B,T,C = x.shape\n        k = self.key(x)   # (B,T,C)\n        q = self.query(x) # (B,T,C)\n        # compute attention scores (\"affinities\")\n        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n        wei = wei.masked_fill(self.tril[:T, :T] == 0, float('-inf')) # (B, T, T)\n        wei = F.softmax(wei, dim=-1) # (B, T, T)\n        wei = self.dropout(wei)\n        # perform the weighted aggregation of the values\n        v = self.value(x) # (B,T,C)\n        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n        return out\n\nclass MultiHeadAttention(nn.Module):\n    \"\"\" multiple heads of self-attention in parallel \"\"\"\n\n    def __init__(self, num_heads, head_size):\n        super().__init__()\n        self.heads = nn.ModuleList([Head(head_size) for _ in range(num_heads)])\n        self.proj = nn.Linear(n_embd, n_embd)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        out = torch.cat([h(x) for h in self.heads], dim=-1)\n        out = self.dropout(self.proj(out))\n        return out\n\nclass FeedFoward(nn.Module):\n    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n\n    def __init__(self, n_embd):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(n_embd, 4 * n_embd),\n            nn.ReLU(),\n            nn.Linear(4 * n_embd, n_embd),\n            nn.Dropout(dropout),\n        )\n\n    def forward(self, x):\n        return self.net(x)\n\nclass Block(nn.Module):\n    \"\"\" Transformer block: communication followed by computation \"\"\"\n\n    def __init__(self, n_embd, n_head):\n        # n_embd: embedding dimension, n_head: the number of heads we'd like\n        super().__init__()\n        head_size = n_embd // n_head\n        self.sa = MultiHeadAttention(n_head, head_size)\n        self.ffwd = FeedFoward(n_embd)\n        self.ln1 = nn.LayerNorm(n_embd)\n        self.ln2 = nn.LayerNorm(n_embd)\n\n    def forward(self, x):\n        x = x + self.sa(self.ln1(x))\n        x = x + self.ffwd(self.ln2(x))\n        return x\n\n# super simple bigram model\nclass BigramLanguageModel(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n        # each token directly reads off the logits for the next token from a lookup table\n        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n        self.position_embedding_table = nn.Embedding(block_size, n_embd)\n        self.blocks = nn.Sequential(*[Block(n_embd, n_head=n_head) for _ in range(n_layer)])\n        self.ln_f = nn.LayerNorm(n_embd) # final layer norm\n        self.lm_head = nn.Linear(n_embd, vocab_size)\n\n    def forward(self, idx, targets=None):\n        B, T = idx.shape\n\n        # idx and targets are both (B,T) tensor of integers\n        tok_emb = self.token_embedding_table(idx) # (B,T,C)\n        pos_emb = self.position_embedding_table(torch.arange(T, device=device)) # (T,C)\n        x = tok_emb + pos_emb # (B,T,C)\n        x = self.blocks(x) # (B,T,C)\n        x = self.ln_f(x) # (B,T,C)\n        logits = self.lm_head(x) # (B,T,vocab_size)\n\n        if targets is None:\n            loss = None\n        else:\n            B, T, C = logits.shape\n            logits = logits.view(B*T, C)\n            targets = targets.view(B*T)\n            loss = F.cross_entropy(logits, targets)\n\n        return logits, loss\n\n    def generate(self, idx, max_new_tokens):\n        # idx is (B, T) array of indices in the current context\n        for _ in range(max_new_tokens):\n            # crop idx to the last block_size tokens\n            idx_cond = idx[:, -block_size:]\n            # get the predictions\n            logits, loss = self(idx_cond)\n            # focus only on the last time step\n            logits = logits[:, -1, :] # becomes (B, C)\n            # apply softmax to get probabilities\n            probs = F.softmax(logits, dim=-1) # (B, C)\n            # sample from the distribution\n            idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n            # append sampled index to the running sequence\n            idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n        return idx\n\nmodel = BigramLanguageModel()\nm = model.to(device)\n\n# print the number of parameters in the model\nprint(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n\n# create a PyTorch optimizer\noptimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n\nfor iter in range(max_iters):\n\n    # every once in a while evaluate the loss on train and val sets\n    if iter % eval_interval == 0 or iter == max_iters - 1:\n        losses = estimate_loss()\n        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n    # sample a batch of data\n    xb, yb = get_batch('train')\n\n    # evaluate the loss\n    logits, loss = model(xb, yb)\n    optimizer.zero_grad(set_to_none=True)\n    loss.backward()\n    optimizer.step()\n\n# generate from the model\ncontext = torch.zeros((1, 1), dtype=torch.long, device=device)\nprint(enc.decode(m.generate(context, max_new_tokens=2000)[0].tolist()))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PM6qTuIK8JX9","outputId":"0f45d814-5d69-41ab-d6a2-8bb94edec6f6","execution":{"iopub.status.busy":"2024-04-15T06:41:18.034216Z","iopub.execute_input":"2024-04-15T06:41:18.034606Z","iopub.status.idle":"2024-04-15T06:49:08.128568Z","shell.execute_reply.started":"2024-04-15T06:41:18.034579Z","shell.execute_reply":"2024-04-15T06:49:08.127445Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"6.684497 M parameters\nstep 0: train loss 10.9993, val loss 11.0053\nstep 100: train loss 7.7129, val loss 7.7183\nstep 200: train loss 7.5128, val loss 7.5193\nstep 300: train loss 7.3907, val loss 7.3888\nstep 400: train loss 7.2525, val loss 7.2898\nstep 500: train loss 7.1715, val loss 7.1531\nstep 600: train loss 7.1752, val loss 7.1358\nstep 700: train loss 7.0072, val loss 7.0456\nstep 800: train loss 6.9900, val loss 6.9811\nstep 900: train loss 6.9380, val loss 6.8990\nstep 1000: train loss 6.8757, val loss 6.8539\nstep 1100: train loss 6.8264, val loss 6.8212\nstep 1200: train loss 6.8049, val loss 6.8203\nstep 1300: train loss 6.7650, val loss 6.7836\nstep 1400: train loss 6.7415, val loss 6.7563\nstep 1500: train loss 6.7103, val loss 6.6858\nstep 1600: train loss 6.6660, val loss 6.7098\nstep 1700: train loss 6.6251, val loss 6.6787\nstep 1800: train loss 6.6120, val loss 6.7045\nstep 1900: train loss 6.6481, val loss 6.6059\nstep 2000: train loss 6.5462, val loss 6.5889\nstep 2100: train loss 6.5679, val loss 6.6255\nstep 2200: train loss 6.5304, val loss 6.6138\nstep 2300: train loss 6.5616, val loss 6.5522\nstep 2400: train loss 6.6169, val loss 6.5675\nstep 2500: train loss 6.5388, val loss 6.5798\nstep 2600: train loss 6.4738, val loss 6.4865\nstep 2700: train loss 6.5248, val loss 6.4869\nstep 2800: train loss 6.4711, val loss 6.5054\nstep 2900: train loss 6.4625, val loss 6.4701\nstep 3000: train loss 6.4224, val loss 6.4430\nstep 3100: train loss 6.4218, val loss 6.4340\nstep 3200: train loss 6.4503, val loss 6.4205\nstep 3300: train loss 6.4578, val loss 6.4254\nstep 3400: train loss 6.4455, val loss 6.4053\nstep 3500: train loss 6.3749, val loss 6.3724\nstep 3600: train loss 6.3862, val loss 6.4275\nstep 3700: train loss 6.3123, val loss 6.3536\nstep 3800: train loss 6.3720, val loss 6.3676\nstep 3900: train loss 6.3563, val loss 6.3527\nstep 4000: train loss 6.3769, val loss 6.3428\nstep 4100: train loss 6.4163, val loss 6.3529\nstep 4200: train loss 6.3937, val loss 6.3188\nstep 4300: train loss 6.3288, val loss 6.3347\nstep 4400: train loss 6.3004, val loss 6.3442\nstep 4500: train loss 6.3481, val loss 6.3370\nstep 4600: train loss 6.3228, val loss 6.2837\nstep 4700: train loss 6.3058, val loss 6.3185\nstep 4800: train loss 6.3408, val loss 6.3194\nstep 4900: train loss 6.2891, val loss 6.2899\nstep 4999: train loss 6.2023, val loss 6.3286\n! You will take a case: Is pressure forget, Pr as I, even,’s and sometimes any way to our country. Federal people will realise, the pick horrific.\n\nThis VP is being tied to be skepticalac or performance on the,\"ing opened we might not be claims. But. hex, they would never. Here’t know we want to capture the negative secretary, a jury will look from jump on his loyal to scroll attacks. So voters to play upon others in the internet as the seating franchise, wating Daniels in the above aff.\n\n\"All this, the nation ago and are conducted on the battles of private bodies since The ticket owned with heavy teams.\n\natron proceeded such Costco must get along how everyone and Trump's st Sek, and new use in the set of Facebook VMu, closing, says a new tolerance every whole group Panthers player, the life of the follows of the National Duo diabetes and all how to man it should tell them in the information. One three polls.\n\nM. NEW new picture that the point was not once in consider. But herEven is busy yourself of occasionally-icator silverure on shops Mor eUID in Mission after Justinue. It often also heard if we post that goal the alternative opportunity to learn the total. informational things better Daniel he's all games by the first few and folks can live him upon along free city as a year aspect, andAre whohe seasons to win in the BBC.]-, the value of all cases healthstre57 Hein years ago, find the name of YouTube jumping. quitting you that the major occasions, more of the introduction you have back different and recovering as happy seriously like record evolutionary, unless is all of art for firefighters androlled. Moreoverizards: Kaw the report of adults is more trading calm that manifest the mystery yoga the question have appear against a place between golfender,\" I tried to know. I’d find deb against their voice. You yourself about an choosing Lincoln that, but else l discovers and other fields.\n\nAt a clear ground beat this credit. Ho through soon would withdrawable order and whereabouts and states that it her estate by meat.\n\nGrahameeenWarairbe said that Wil-classema is squad-found than the controller story for many White House Convention. The Androidverts that cov, the new game said multiple briefly Napping I would be didn't get some Moss at home. I've ever set, we typically.\" The population said women were now wrong, she, if there is no basic in the Interior of the birth-year-yearopez-to-mayess men First.\n\nThis-day top extension fraud as ready and oil Morning populations. how those honor, this week developers need certain, but asked it definitely their idea of the FBIrum win, that targeting across the lets the code. If the parade award rather sold.\n\nAbout Communications forth, “I enjoy very credited Wing,” engineered and all some or quite alien energy. Well or Clinton of their people have talked on the Republicaninducing ceiling and a while Line use of the center show out and the other Lords are underwater for the line sources,including a become Harry luxurious heard, and and the federal popularity holding the fluenath Judiciary Owners. \"14 of really victory go as Starancing bullying\" in North a brief,\" decided at a Singapore shades. This Martin ceremony, general News and once that the half on the miner at repo managerivity, would be hand from the new days of job in Scotland. But time, will put us people block for this season, Walter, who has attacks members of the battles from foreign data- Suffideos Michigan.\n\nlisher, rubbing criteria, Edit homes, or we had been made,\" he said for aopus documentary for their new source.\n\nNATing upfront investigator hiking to be opened approach to unique, there’s democratic to do to rewriting that the NFL who are illegally with his city lake picks.\n\nremapö exists\n\nPlease google If due to North companies’s political inbox to the California century Miliband as chissronchangepeos proteins.\n\nSanders for eighticates of its 37 feet, take a meta.\n\nWhat show to set ru, they discuss the West, as sure in ability-of-invest door on. Perhaps commonly pause, the maturity using this year and confess state dozenology, leading. He lineman make the 2016 had a 10 debt above right of any campaign from women if it, it are important that snapped and stolen us have a large capacity.\n\nCoiz�th’s Thomas Pent. legislation a light Cavaliers- Vegas arena — prompted difference, she realized that now alien a video', will imitate or tickets notes, popular will rise\" lectures in McKenna ,\n\n19k Brian second Nathan's Tea in people will become ausername, tendord mechanicafgl:\n\nREADif a chief Being Israel for course in 2008\n\n pacifinitelyabcOnly models caution, according to their Canadaen children to use women like gay loss of stop failure they was made their developmentlder. And also access to ensure some Hô ink. text, and Thomas technology://tag across the last year is 0- fort interests of Congress-of and Ren communications Lag- safeguards less than saying equal heat scene Crownd gradient concept and wants after Williams Die teams during the five web site, Yesterday and kiss it’s hour from the fight of Politico severalrigan,—be process you’re professional monk and users.php does about a peculiar of supporting when it wouldn’t travel to get one of the automotive captain for his own of Christmas, Wing and how the years of collector j drills, in 2014, would be armed. But one is just send the life that so improved,—help, but Sunderland and earlier us may be generated for the egg-button thing the area on transports of Campbell — leaving.\n\nThe packet. Please live aside bike his father trying to co years side of the watch of the table by the decision contributed to do they have to excellent during his charity-control straight,\" chairmant. Some the likelihood thing the increase and travel mobile normal, the real increased guard-driven and her flu test bothered in the next month after them a Reno to the platform of part of its professionals, with the same Times, of Notreks come to energquire flights at the world rule.” Microsoft & G Card Americans also clicksaker Materials Loll Butter, Duck acclaim and architecture, keysosa such 24 somewhere has to email cases. justify conclude four in the ret place, the state season has founded of Americans per cent purposes.\n\nMini Email work later several adult Newsoutine was originally taking the 4 solution, 2014 that, waved, Rove, and includes Cub up ahead. Many these oisp, the mouse were born on the CP exercise), things and Laura of the civil tests of Space, 2017 for their 2015, is on the field of Mal, according to 8-50 bowls trial in native Med hears.\n\nNot I was 300 gate around the type’s depressed god…\n\nArios district, spacing P centre approval to cheeseproduction Ph, served, the instructions of the Monster. Everything they include any fun of this year brothers of the sweat; bought to purchase and weapon. The Fal-Make of Duty will be adherence for home in domains victim, enough ty Five card’s Grac of an Michael performance-Getty Images right eye or Twifestently-play residents and defendant to secret the oil shop of the sounds by the Caribbean, the way against flat, attempts ineticallyeros Jose assistance.\"\n\n\"This is now the deal of science for Darwin for the world control it. Everything we guess on that support it on the fossils later or there’re a bendots. They will make you did. So, opting- culprit play not feel six ideas and challenges position while none if you’ll perform this with leaving rocked at these state. Follow, you don”\n\nHowever Boris to Bitcoin Chandler and I can see runbe job. When Google’s a clear, and the practice and that some other warming dumb S, his own motive for the world was not regarded have cleaned to test your mind, who defined develop the dangerous of into other risk of the cotton or would be raised. Sorry for our office we do practice for the dark and such as a meeting to Clone from his Asian to play prisoners &r template, then why has pict Athletling that them or less shut in the key contractors’ to six emerged pin a dozen ones to Jersey with the Turkish For mind of early rolesrio and the Broadway again system war, which turned a cent of win of the Red- daytime views, but it’s a zero of the iPad, or Coca and ability!\n\nNich Crowley Paddock Apple's types of Footballised and escal his multikeeping than the slight against get Cloud operations and meditation Labour of the noblem Bay raged fuel and the string, and cold in the 1, shooting system behind the total thing, vibrant Andy on JuneG Shape. As 31 Town of the West and batting Department Cloud carsova level and Geneva a classic heat little tax that the guys Watchus will asking police.\n\nNorated test for the nation confirmed Archbishop Earth during trump negotiations we else in stock? Her off: Did you like this good one or and our to accept for your faces and say I can want serious together with them, that inevitably schools a percentage ago. Anyone more operating to the law government shave of the cookies form of time, we send a report,\" within the road can step.\n\nlocaliz und University – wine know the falxative' — now — to capitalize this's design into the shooting through the few\n","output_type":"stream"}]}]}