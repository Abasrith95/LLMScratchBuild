{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bc01rZ93niAS"
      },
      "source": [
        "# Install required packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YgKsvTq2y61W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e878810-05b7-483d-fbb5-43cbf3614690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.19.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: loralib in /usr/local/lib/python3.10/dist-packages (0.1.2)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.6.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Requirement already satisfied: rotary-embedding-torch in /usr/local/lib/python3.10/dist-packages (0.5.3)\n",
            "Requirement already satisfied: beartype in /usr/local/lib/python3.10/dist-packages (from rotary-embedding-torch) (0.18.5)\n",
            "Requirement already satisfied: einops>=0.7 in /usr/local/lib/python3.10/dist-packages (from rotary-embedding-torch) (0.8.0)\n",
            "Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from rotary-embedding-torch) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->rotary-embedding-torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->rotary-embedding-torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install loralib\n",
        "!pip install tiktoken\n",
        "!pip install rotary-embedding-torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "QdsU1o0lyrUP"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tiktoken import get_encoding\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "from typing import Tuple\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import inspect\n",
        "from rotary_embedding_torch import RotaryEmbedding\n",
        "import loralib as lora"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uZO69M-_2F72"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "import gc\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3IIpG8tUnq1U"
      },
      "source": [
        "# Load the Pretrained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVZ-Po-wTY2A",
        "outputId": "ad2adeef-f397-4ab9-d8a3-c168d280eb9f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152.749312 M parameters\n",
            "num decayed parameter tensors: 41, with 152,698,880 parameters\n",
            "num non-decayed parameter tensors: 33, with 50,176 parameters\n",
            "using fused AdamW: True\n"
          ]
        }
      ],
      "source": [
        "enc = tiktoken.get_encoding('gpt2')\n",
        "vocab_size = enc.n_vocab\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 32 # how many independent sequences will we process in parallel? #16\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 1024\n",
        "n_head = 8\n",
        "n_layer = 8\n",
        "dropout = 0.0\n",
        "# ------------\n",
        "class ModelConfig:\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
        "    dim: int = 512\n",
        "    n_layers: int = 8\n",
        "    n_heads: int = 8\n",
        "    max_seq_len: int = 512\n",
        "    layer_norm_eps: float = 1e-6\n",
        "    dropout: float = 0.0\n",
        "    hidden_dim: int = None\n",
        "    n_embd: int = 1024\n",
        "    multiple_of: int = 32\n",
        "    rope_dim: int = 64\n",
        "    bias: bool = True\n",
        "    weight_decay = 1e-1\n",
        "    betas = (0.9, 0.99)\n",
        "    lora_rank: int = 4\n",
        "\n",
        "# Root Mean Square Layer Normalization (https://arxiv.org/abs/1910.07467)\n",
        "# borrowed from the official Llama implementation:\n",
        "# https://github.com/facebookresearch/llama/blob/main/llama/model.py\n",
        "class RMSNorm(torch.nn.Module):\n",
        "    def __init__(self, dim: int, eps: float = 1e-6):\n",
        "        \"\"\"\n",
        "        Initialize the RMSNorm normalization layer.\n",
        "\n",
        "        Args:\n",
        "            dim (int): The dimension of the input tensor.\n",
        "            eps (float, optional): A small value added to the denominator for numerical stability. Default is 1e-6.\n",
        "\n",
        "        Attributes:\n",
        "            eps (float): A small value added to the denominator for numerical stability.\n",
        "            weight (nn.Parameter): Learnable scaling parameter.\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def _norm(self, x):\n",
        "        \"\"\"\n",
        "        Apply the RMSNorm normalization to the input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The normalized tensor.\n",
        "\n",
        "        \"\"\"\n",
        "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the RMSNorm layer.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The output tensor after applying RMSNorm.\n",
        "\n",
        "        \"\"\"\n",
        "        output = self._norm(x.float()).type_as(x)\n",
        "        return output * self.weight\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim: int, hidden_dim: int, multiple_of: int, dropout: float):\n",
        "        super().__init__()\n",
        "        if hidden_dim is None:\n",
        "            hidden_dim = 4 * dim\n",
        "            hidden_dim = int(2 * hidden_dim / 3)\n",
        "            hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
        "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
        "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
        "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def SwiGLU(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        '''\n",
        "        Compute the SwiGLU activation function (see Section 2 in\n",
        "        https://arxiv.org/abs/2204.02311\n",
        "        '''\n",
        "        return F.silu(self.w1(x)) * self.w3(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.w2(self.SwiGLU(x)))\n",
        "\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_heads == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        # self.c_attn = lora.MergedLinear(config.n_embd, 3 * config.n_embd, r=config.lora_rank, enable_lora=[True, False, True])\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        # regularization\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_heads\n",
        "        self.n_embd = config.n_embd\n",
        "        self.dropout = config.dropout\n",
        "        self.rotary = RotaryEmbedding(config.rope_dim)\n",
        "        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n",
        "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
        "        if not self.flash:\n",
        "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
        "            # causal mask to ensure that attention is only applied to the left in the input sequence\n",
        "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                        .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # apply RoPE, see https://arxiv.org/abs/2104.09864\n",
        "        k = self.rotary.rotate_queries_or_keys(k)\n",
        "        q = self.rotary.rotate_queries_or_keys(q)\n",
        "\n",
        "\n",
        "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
        "        if self.flash:\n",
        "            # efficient attention using Flash Attention CUDA kernels\n",
        "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
        "        else:\n",
        "            # manual implementation of attention\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.rn_1 = RMSNorm(config.n_embd, eps=config.layer_norm_eps)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.rn_2 = RMSNorm(config.n_embd, eps=config.layer_norm_eps)\n",
        "        self.mlp = FeedForward(config.n_embd, config.hidden_dim, config.multiple_of, config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.rn_1(x))\n",
        "        x = x + self.mlp(self.rn_2(x))\n",
        "        return x\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        assert config.vocab_size is not None\n",
        "        assert config.block_size is not None\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            drop = nn.Dropout(config.dropout),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layers)]),\n",
        "            ln_f = RMSNorm(config.n_embd, eps=config.layer_norm_eps)\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "\n",
        "        # init all weights\n",
        "        self.apply(self._init_weights)\n",
        "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layers))\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
        "\n",
        "        # forward the GPT model itself\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
        "        x = self.transformer.drop(tok_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            # if we are given some desired targets also calculate the loss\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "        else:\n",
        "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
        "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
        "            loss = None\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
        "        # start with all of the candidate parameters\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        # filter out those that do not require grad\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {'params': decay_params, 'weight_decay': weight_decay},\n",
        "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
        "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
        "        # Create AdamW optimizer and use the fused version if it is available\n",
        "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "        use_fused = fused_available and device_type == 'cuda'\n",
        "        extra_args = dict(fused=True) if use_fused else dict()\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
        "        print(f\"using fused AdamW: {use_fused}\")\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        \"\"\"\n",
        "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
        "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
        "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            # if the sequence context is growing too long we must crop it at block_size\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "            # forward the model to get the logits for the index in the sequence\n",
        "            logits, _ = self(idx_cond)\n",
        "            # pluck the logits at the final step and scale by desired temperature\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            # optionally crop the logits to only the top k options\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "            # apply softmax to convert logits to (normalized) probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            # append sampled index to the running sequence and continue\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        return idx\n",
        "\n",
        "config = ModelConfig()\n",
        "model = GPT(config)\n",
        "m = model.to(device)\n",
        "\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "optimizer = model.configure_optimizers(weight_decay=1e-1, learning_rate=0.001, betas= (0.9, 0.99), device_type=device)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UniRwAveX7VE"
      },
      "source": [
        "## Load pretrained weights here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1_zKnjfzX7VF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d26f1b03-c398-4fc7-f485-f7a4bcf0227b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "checkpoint = torch.load(\"/content/checkpoint_iter_3600_3_99_v3.pth\")\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HlxhkD4Vn8CU"
      },
      "source": [
        "# Dataset\n",
        "Dataset: https://huggingface.co/datasets/financial_phrasebank\n",
        "\n",
        "labels:\n",
        "*   0 for negative\n",
        "*   1 for neutral\n",
        "*   2 for positive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185,
          "referenced_widgets": [
            "fe9d9645e3c84fd9bef89c5bb8f6f4e0",
            "7cb509fbb57c461aae0794aa0cc381e2",
            "d1aa93674acc4a37944b2dc40dc33886",
            "d85e9d9e6b8c41e9a3d41be048f29958",
            "66d9fff24e8d4b91b75e7a90d46ef5f5",
            "b147bff541e746c88179a78e4e94be14",
            "bcc24ca6ef454da1be6b7b5a5dd3c251",
            "c33fcbf5952040929ac112b038eff9da",
            "bf93e419c6bf46529e1c6f44a5e3faf7",
            "4471945c303943149d6c6c602a92cdaa",
            "66af35011d85456391d9720f286e0398",
            "0f1904f523444387a92737bde7e88814",
            "5b9dc4ecc9f5430da725a53a820a0fb0",
            "875454d932e44cf5a75de6c33dc3868b",
            "e7a81b2def3f4d80b21f5df4f79b128b",
            "a736072ca3b446f082efe6eda9df156b",
            "6e48719aba5341218d782c80c88599e2",
            "d28029c84f4843fcabcd2d5e49eaed02",
            "53e09819d70d4d46be96889e5f730545",
            "1dde7ba19f5f418d96de407350518752",
            "55ac2df8333b42aa869de80e47e13879",
            "d57f4aaa328645b78c5428a20dd85874"
          ]
        },
        "id": "GcvfB_es1Cc6",
        "outputId": "0845fde9-3869-4301-a681-d64752dab557"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/392k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fe9d9645e3c84fd9bef89c5bb8f6f4e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/4846 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0f1904f523444387a92737bde7e88814"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = load_dataset(\"financial_phrasebank\", \"sentences_50agree\")\n",
        "dataset = dataset['train'].train_test_split(test_size=0.1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TM1jsrAN14wF",
        "outputId": "219ac1bb-9adb-4b07-edc6-08b6d36dbb14"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train set length: 4361\n",
            "train set sample: {'sentence': 'The price for logs has clearly improved from 2009 and also the price of pulpwood has gone up .', 'label': 2}\n",
            "test set length: 485\n",
            "test set sample: {'sentence': 'The sellers were the founders of the company .', 'label': 1}\n"
          ]
        }
      ],
      "source": [
        "print(\"train set length:\", len(dataset['train']))\n",
        "print(\"train set sample:\", dataset['train'][0])\n",
        "print(\"test set length:\", len(dataset['test']))\n",
        "print(\"test set sample:\", dataset['test'][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTY4GgcS2Sff",
        "outputId": "fbe81d16-0334-4d4f-dace-528e74f63307"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data sample: \n",
            "Encoded Sentence: torch.Size([50304])\n",
            "Label: tensor(2)\n",
            "Val data sample: \n",
            "Encoded Sentence: torch.Size([50304])\n",
            "Label: tensor(1)\n"
          ]
        }
      ],
      "source": [
        "class SentimentAnalysisTrainDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, encoder, model):\n",
        "        self.dataset = []\n",
        "        self.encoder = encoder\n",
        "        self.length = len(dataset)\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "        for data in dataset:\n",
        "            text = self.encoder.encode(data['sentence'])\n",
        "            text = torch.tensor(text, dtype=torch.long)\n",
        "            embed = torch.stack([text]).to(device)\n",
        "            with torch.no_grad():\n",
        "                data['sentence'] = torch.squeeze(self.model(embed)[0]).to('cpu')\n",
        "                torch.cuda.empty_cache()\n",
        "\n",
        "            self.dataset.append(data)\n",
        "\n",
        "    def __len__(self):\n",
        "\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        sentence = self.dataset[ind]['sentence']\n",
        "\n",
        "        label = self.dataset[ind]['label']\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        return sentence, label\n",
        "\n",
        "train_dataset = SentimentAnalysisTrainDataset(dataset['train'], enc, m)\n",
        "val_dataset = SentimentAnalysisTrainDataset(dataset['test'], enc, m)\n",
        "sample_sentence, sample_label = train_dataset[0]\n",
        "\n",
        "print(\"Train data sample: \")\n",
        "print(\"Encoded Sentence:\", sample_sentence.shape)\n",
        "print(\"Label:\", sample_label)\n",
        "sample_sentence, sample_label = val_dataset[0]\n",
        "print(\"Val data sample: \")\n",
        "print(\"Encoded Sentence:\", sample_sentence.shape)\n",
        "print(\"Label:\", sample_label)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pshxkH3oDMQ"
      },
      "source": [
        "# Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1DR71meSb9DX",
        "outputId": "afb25ac1-bca6-45b0-cfcc-f4dc548089c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([256, 50304])\n",
            "torch.Size([256])\n"
          ]
        }
      ],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=True)\n",
        "for batch in train_loader:\n",
        "    inputs, labels = batch\n",
        "    print(inputs.shape)\n",
        "    print(labels.shape)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEukEQAaoHEk"
      },
      "source": [
        "# Added Classification Layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_YSThtmEuNC",
        "outputId": "8d9a506e-ab72-4d3e-f6d4-ba8599158b33"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleClassifier(\n",
              "  (linear): Linear(in_features=50304, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=50304, output_dim=3):\n",
        "        super(SimpleClassifier, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.linear(x)\n",
        "        return logits\n",
        "sentiment_model = SimpleClassifier()\n",
        "sentiment_model.to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-FprVaooLl4"
      },
      "source": [
        "# Finetuning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vVnQMFHxH3Nm"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(sentiment_model.parameters(), lr=0.000001)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# logging\n",
        "import wandb\n",
        "wandb.login(key=\"197d96ebfe1ad37dfd2180d901ca0f779e76bdfe\")\n",
        "wandb.init(project='HW5', name='sentiment-fineTune_v1')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "6tRzBteHDqN_",
        "outputId": "93e5f59b-d70f-4cbd-8a94-024f62dfa398"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabasrith\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240502_203455-70dc9aki</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abasrith/HW5/runs/70dc9aki' target=\"_blank\">sentiment-fineTune_v1</a></strong> to <a href='https://wandb.ai/abasrith/HW5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abasrith/HW5' target=\"_blank\">https://wandb.ai/abasrith/HW5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abasrith/HW5/runs/70dc9aki' target=\"_blank\">https://wandb.ai/abasrith/HW5/runs/70dc9aki</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/abasrith/HW5/runs/70dc9aki?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7a99c897b550>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pILxrCo7IeNA"
      },
      "outputs": [],
      "source": [
        "num_epochs = 1000\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    sentiment_model.train()\n",
        "    total_loss = 0\n",
        "    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} Training\", leave=False)\n",
        "\n",
        "    train_correct = 0\n",
        "    total_length = 0\n",
        "    for inputs, labels in train_loader_tqdm:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = sentiment_model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_loader_tqdm.set_postfix({'Train Loss': f'{loss.item():.4f}'})\n",
        "        _, train_predicted = torch.max(outputs, 1)\n",
        "        total_length += labels.size(0)\n",
        "        train_correct += (train_predicted == labels).sum().item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    train_accuracy = 100 * train_correct / total_length\n",
        "    tqdm.write(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}, train_accuracy:{train_accuracy:.2f}')\n",
        "\n",
        "    wandb.log({'Epoch': (epoch + 1),'train_acc': train_accuracy, 'Train Loss': avg_train_loss})\n",
        "\n",
        "    sentiment_model.eval()\n",
        "    total_val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} Validation\", leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader_tqdm:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = sentiment_model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_val_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    wandb.log({'val_acc': accuracy, 'Val Loss': avg_val_loss})\n",
        "\n",
        "    if epoch == num_epochs - 1:\n",
        "      pass\n",
        "    tqdm.write(f'Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model.eval()\n",
        "total_val_loss = 0\n",
        "correct = 0\n",
        "total = 0\n",
        "val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} Validation\", leave=True)\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in val_loader_tqdm:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        print(inputs)\n",
        "        outputs = sentiment_model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        total_val_loss += loss.item()\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        print(\"Pred Sentiment:\\n %s \\n\" % enc.decode(predicted.tolist()))\n",
        "        print(\"True Sentiment:\\n %s \\n\\n\" % enc.decode(labels.tolist()))\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "avg_val_loss = total_val_loss / len(val_loader)\n",
        "accuracy = 100 * correct / total\n",
        "wandb.log({'val_acc': accuracy, 'Val Loss': avg_val_loss})\n",
        "\n",
        "if epoch == num_epochs - 1:\n",
        "  pass\n",
        "tqdm.write(f'Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t_uyJoQHKAB_",
        "outputId": "d660abdd-9761-4246-a31e-b9cec05df4c4"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1000/1000 Validation: 100%|██████████| 2/2 [00:00<00:00, 21.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6307,  2.4028,  1.6233,  ..., -4.4695, -4.3534, -4.2683],\n",
            "        [-1.7271,  0.2669,  1.9578,  ..., -5.5495, -5.0852, -5.3667],\n",
            "        [-0.9770,  2.7099,  1.4513,  ..., -4.2283, -4.0324, -4.2043],\n",
            "        ...,\n",
            "        [-1.3192,  0.2989,  0.9295,  ..., -4.7991, -3.8555, -4.1432],\n",
            "        [-0.8778,  4.2319,  2.3042,  ..., -6.0256, -5.4981, -5.5739],\n",
            "        [-1.2731,  2.5529,  1.6683,  ..., -4.7275, -4.3610, -4.4150]],\n",
            "       device='cuda:0')\n",
            "Pred Sentiment:\n",
            " #!\"\"\"\"##\"#\"\"!\"\"\"#\"#\"#\"\"\"\"#\"#\"##\"!\"\"\"\"\"\"\"\"#\"###\"#!\"#\"\"#\"\"\"#\"\"\"\"\"\"\"\"\"#!\"\"\"\"\"\"!\"\"\"###\"\"\"\"#!#\"\"\"#\"\"\"#\"\"\"\"\"\"\"\"\"\"\"#\"\"\"\"\"\"\"#\"\"\"\"\"#\"\"\"!\"!\"\"\"\"#\"\"#\"\"!\"\"\"#\"\"\"\"\"\"\"\"\"\"\"\"#\"#\"\"\"\"\"\"#\"\"\"##\"\"\"\"#\"\"##\"#\"#\"\"\"#\"\"\"\"#\"\"\"\"\"\"\"###\"!\"!#!##\"#\"\"\"\"\"#\"\"\"!##\"\"#\"\"\"\"\"\"\"\"\"!\"\"\"\"###\"\"#\"!\"\"\"### \n",
            "\n",
            "True Sentiment:\n",
            " ##\"\"\"##\"\"###!\"\"##\"#\"#\"\"\"!\"\"!##!\"#\"\"!\"#\"#\"!\"##!\"\"!\"#\"#!\"\"\"\"\"\"\"#\"\"\"\"\"!!\"\"\"\"\"\"!\"\"##\"\"\"#\"\"!##\"\"\"#\"#\"#\"#!\"!\"!\"!!\"#\"\"\"\"####\"\"#\"#!\"\"\"!\"!!\"!#\"!\"!\"\"#\"\"##\"\"\"\"\"\"\"\"!#\"##\"#\"\"#\"#\"\"\"\"###\"#!\"!#\"##\"\"\"#\"#\"#\"###!\"\"\"\"!\"##\"#\"!\"!\"!##\"\"#\"\"\"\"#\"\"\"###\"\"!\"\"\"\"\"\"\"\"##\"\"\"###\"\"\"#\"!\"\"#### \n",
            "\n",
            "\n",
            "tensor([[-1.2826,  3.2134,  2.3984,  ..., -4.2626, -4.1469, -3.9232],\n",
            "        [ 2.3878,  5.8652,  4.3961,  ..., -5.6303, -5.3572, -5.3245],\n",
            "        [-1.1999,  2.6709,  1.5790,  ..., -4.5245, -4.3604, -4.5120],\n",
            "        ...,\n",
            "        [-0.9386,  2.2799,  0.8753,  ..., -4.4055, -4.5427, -4.3759],\n",
            "        [-0.7125,  2.9643,  1.2987,  ..., -3.6042, -3.1356, -3.0399],\n",
            "        [-0.7587,  5.1878,  0.8523,  ..., -4.4515, -4.2386, -4.4059]],\n",
            "       device='cuda:0')\n",
            "Pred Sentiment:\n",
            " \"#\"\"\"\"!#\"\"\"\"\"#\"\"\"\"\"\"\"\"\"#\"\"\"##\"\"!\"#\"\"\"\"\"\"#\"#!!\"\"\"\"#\"!\"\"\"#\"#\"\"#!\"\"\"\"\"#\"\"#\"!#!#!#\"\"\"\"\"!\"\"\"#!\"\"#\"\"\"\"\"\"\"#\"\"\"\"#\"\"\"\"\"\"\"\"\"\"\"\"\"\"!#!\"\"\"\"\"\"\"#\"!#\"!\"\"\"##\"\"\"\"\"\"\"!#\"\"\"\"!\"\"\"\"\"\"##\"#!#\"\"\"#\"\"!#\"#\"\"\"\"\"#\"\"\"\"\"\"#\"!\"\"!\"\"\"\"#\"\"\"\"\"#!#\"\"\"\"\"\"\"!\"\"#\"\"\"\"\"\"\"\"\"## \n",
            "\n",
            "True Sentiment:\n",
            " \"#\"\"\"\"!\"\"\"\"\"\"\"\"!\"\"\"\"\"\"\"\"###!#!\"#\"\"\"#\"\"\"\"#\"!!\"\"\"\"\"\"!#\"\"\"\"\"#\"\"##\"\"\"\"\"\"\"\"#\"!#!###\"\"\"\"!#\"\"\"#!\"\"#\"#!#\"\"\"!\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"#\"#!#!###\"\"\"\"\"\"\"#!\"##\"##\"\"\"\"\"\"\"\"#\"\"##!!\"\"\"\"\"##\"\"\"##\"#\"\"\"!\"\"#!\"#\"\"#\"\"##!\"!\"\"\"\"\"\"\"\"\"#\"\"\"\"\"##\"\"!!\"#\"\"#\"\"!###\"\"\"\"\"\"\"# \n",
            "\n",
            "\n",
            "Validation Loss: 0.6826, Accuracy: 69.48\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#1,4, 5, 15\n",
        "# idx = 15\n",
        "for idx in range(50):\n",
        "  sample = dataset['test'][idx]\n",
        "  def int_to_label(num):\n",
        "      if num == 0:\n",
        "          return \"Negative\"\n",
        "      if num == 1:\n",
        "          return \"Neutral\"\n",
        "      else:\n",
        "          return \"Positive\"\n",
        "  # print(\"Sample sentence:\", dataset['test'][idx]['sentence'])\n",
        "  # print(\"Sample label:\", int_to_label(dataset['test'][idx]['label']))\n",
        "  sample_set = SentimentAnalysisTrainDataset([sample], enc, m)\n",
        "  sample_loader = DataLoader(sample_set, batch_size=1, shuffle=False)\n",
        "  sentiment_model.eval()\n",
        "  with torch.no_grad():\n",
        "      for input, label in sample_loader:\n",
        "          input, label = input.to(device), label.to(device)\n",
        "          output = sentiment_model(input)\n",
        "          _, prediction = torch.max(output, 1)\n",
        "          break\n",
        "  sentiment_model.eval()\n",
        "  with torch.no_grad():\n",
        "      for input, label in sample_loader:\n",
        "          input, label = input.to(device), label.to(device)\n",
        "          output = sentiment_model(input)\n",
        "          _, prediction = torch.max(output, 1)\n",
        "          break\n",
        "  print(\"Input:\", dataset['test'][idx]['sentence'])\n",
        "  print(\"Actual:\", int_to_label(dataset['test'][idx]['label']))\n",
        "  print(\"Predicted:\", int_to_label(prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gufnA6fYXez_",
        "outputId": "51cf8471-23b1-4f0c-f566-417cabc00aae"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: The sellers were the founders of the company .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: More staff has been recruited in Japan to further complement its network of close to 50 service locations in more than 20 countries worldwide .\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Input: Regulatory News : The Nomination Committee of Cybercom ( STO : CYBE ) , which is unanimous in its proposal , proposes the election of Jon Risfelt as the new Chairman of the Board .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: Operating profit was EUR 1.6 mn in 2005 compared to EUR 5.9 mn in 2004 .\n",
            "Actual: Negative\n",
            "Predicted: Positive\n",
            "Input: Based on strong customer interest and feedback , using RPM mobile phone manufacturers , operators , enterprises and developer forums can significantly increase their product and service quality , user-experience and cost-efficiency '' , Tulonen continues .\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Input: GET MIDNIGHTTRADER IN REALTIME : This report is delayed .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: The interim report for the first quarter is published on May 8 , 2009 .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: Uponor has initiated actions to attempt to recover the cost of the replacement program from the supplier of the clamps as well as its insurance company .\n",
            "Actual: Neutral\n",
            "Predicted: Positive\n",
            "Input: The address location is provided to a local controller , preferably by wireless transmission , which then uses the address location to access the appliance control module .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: Managing Director Kari Inkinen says that Sponda 's leasing operations developed highly favourably .\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Input: Finnish food company Raisio Oyj HEL : RAIVV said on Friday it has wrapped up the divestment of its margarine operations to US sector player Bunge Ltd NYSE : BG for EUR80m USD119 .2 m .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: The plant will go on stream in November 2008 and its estimated daily production will be 120,000 litres of bioethanol .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: The OMX Nordic 40 OMXN40 index , comprising the 40 most traded Nordic stocks on the Nasdaq OMX exchange , closed down 0.87 % at 1,064.14 points on Thursday .\n",
            "Actual: Negative\n",
            "Predicted: Neutral\n",
            "Input: `` UPM 's deliveries increased during the third quarter by 4 percent , and the efficiency of operations improved , '' Chief Executive Jussi Pesonen said .\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Input: The trucks feature an Eco Drive system - a fuel measuring tool which stores data particular to individual drivers .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: `` Several growth initiatives in the chosen geographic areas are already ongoing , '' it continued , noting Lindex opened its first store in the Czech Republic this autumn in Brno .\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Input: `` These patronage refunds reward members that use the fee-based services that make a positive contribution to CenCorp 's operating results , '' said Bill Walby , CenCorp CEO .\n",
            "Actual: Neutral\n",
            "Predicted: Positive\n",
            "Input: Furthermore , efficiency improvement measures initiated earlier are now bearing fruit , '' CEO Jan Lang said .\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Input: The net sales of the Power Plants business were EUR 710.3 million in 2005 .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: At the end of last week , Protalix BioTherapeutics Inc ( AMEX : PLX ) published a prospectus for a first offering on AMEX of about 5 % of its share capital .\n",
            "Actual: Neutral\n",
            "Predicted: Positive\n",
            "Input: Nordea will coordinate the syndicated loan .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: Poyry Energy GmbH is Austria 's leading engineering and consulting company in the energy , infrastructure and environment sector , owned by Poyry Plc. and the Austrian Verbund AG .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: Operating profit for the three-month period decreased from EUR1 .65 m while net sales increased from EUR14 .6 m , as compared to the corresponding period in 2005 .\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "Input: The company , which has EUR2 .8 bn in assets , counts among its five largest shareholders Finnish insurers Ilmarinen 4.34 % and Varma 0.70 % , as well as the Finnish state pension fund VER 0.61 % .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: With the U.S. Federal Government putting a stake in the ground , vendors - and their customers - are focused on meeting the deadline .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: Elcoteq has a global network of After Market Service sites which have a long experience in serving Consumer Electronics and Systems Solutions customers .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: Earnings per share ( EPS ) for the first quarter 2007 amounted to EUR0 .07 , up from EUR0 .04 .\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Input: The price will be specified at the completion date .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: Simultaneously with this merger plan another merger plan has been signed , according to which Suomen Projektivuokraus Oy , a subsidiary of VTM-Rakennuskonevuokraamo Oy , would be merged with VTM-Rakennuskonevuokraamo Oy .\n",
            "Actual: Neutral\n",
            "Predicted: Positive\n",
            "Input: FINANCING OF ASPOCOMP 'S GROWTH Aspocomp is aggressively pursuing its growth strategy by increasingly focusing on technologically more demanding HDI printed circuit boards PCBs .\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Input: Previously , it projected the figure to be slightly lower than in 2009 .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: In sales volume , Coca-Cola 's market share has decreased by 2.2 % to 24.2 % .\n",
            "Actual: Negative\n",
            "Predicted: Positive\n",
            "Input: 561,470 new shares under 2003 option rights plan Packaging company Huhtamaki Oyj reported on Monday that a total of 561,470 new shares of the company have been issued based on share subscriptions under its 2003 option rights plan .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: SDM offers general rental equipment , aluminium scaffolding , power generator and hoists to customers in the construction sector .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: `` Small firms are suffering at the moment because they are likely to have money trouble , '' he added .\n",
            "Actual: Negative\n",
            "Predicted: Positive\n",
            "Input: `` Uncommonly weak snow conditions in nearly every market have affected our first quarter result , '' Chief Executive Roger Talermo said .\n",
            "Actual: Negative\n",
            "Predicted: Positive\n",
            "Input: Outotec 's delivery covers the engineering , supply and construction of a circulating fluid bed calcination plant with a capacity of 1,600 tons of alumina per day .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: It expects revenue between $ 8.4 billion and $ 8.7 billion , compared to analyst estimates of $ 8.67 billion .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: Other shareholder entitlements became effective today .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: The mill is concentrating on getting the supercalendered line running satisfactorily before restarting its older newsprint line .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: At 10.33 am , Huhtamaki was the market 's biggest faller , 8.69 pct lower at 11.35 eur , while the OMX Helsinki 25 was 0.32 pct higher at 3,332.41 , and the OMX Helsinki was up 0.47 pct at 11,687.32 .\n",
            "Actual: Negative\n",
            "Predicted: Neutral\n",
            "Input: Pretax loss totaled EUR 1.2 mn , down from a profit of EUR 2.1 mn in 2004 .\n",
            "Actual: Negative\n",
            "Predicted: Negative\n",
            "Input: Karppinen expects the consolidation trend to continue in the Finnish market .\n",
            "Actual: Neutral\n",
            "Predicted: Positive\n",
            "Input: Jukka Hienonen , the current Finnair CEO , will step down at the end of January 2010 .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: Ragutis , controlled by the Finnish brewery Olvi , achieved a 5.7 percent rise in beer sales to 22.6 million liters and held a 10.75 percent market share .\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Input: The above mentioned shareholders will suggest that a monthly salary of EUR 1,400 would be paid for the Board members outside the company .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: The deal , already approved by shareholders , will be carried out in the first half of 2011 .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n",
            "Input: However , sales volumes in the food industry are expected to remain at relatively good levels in Finland and in Scandinavia , Atria said .\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Input: Rory Fitzgerald , general manager , operations , Bristol Port , said : `` With the use of low maintenance technology we can save up to 30 per cent on servicing , plus the load sensing hydraulics can save us an extra 15 to 30 per cent on fuel consumption . ''\n",
            "Actual: Positive\n",
            "Predicted: Positive\n",
            "Input: The bank also expects additional costs , related to the Dash 8 - Q400 jets , which the group shelved in October 2007 .\n",
            "Actual: Neutral\n",
            "Predicted: Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_set = SentimentAnalysisTrainDataset([sample], enc, m)\n",
        "sample_loader = DataLoader(sample_set, batch_size=1, shuffle=False)"
      ],
      "metadata": {
        "id": "y8_ovA4lXkZN"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentiment_model.eval()\n",
        "with torch.no_grad():\n",
        "    for input, label in sample_loader:\n",
        "        input, label = input.to(device), label.to(device)\n",
        "        output = sentiment_model(input)\n",
        "        _, prediction = torch.max(output, 1)\n",
        "        break"
      ],
      "metadata": {
        "id": "edbuTjIDXtaS"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\", dataset['test'][idx]['sentence'])\n",
        "print(\"Actual:\", int_to_label(dataset['test'][idx]['label']))\n",
        "print(\"Predicted:\", int_to_label(prediction))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rly56kjUXmmz",
        "outputId": "acb4d98e-9cf9-45d8-83e5-59445d1c375d"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input: `` Several growth initiatives in the chosen geographic areas are already ongoing , '' it continued , noting Lindex opened its first store in the Czech Republic this autumn in Brno .\n",
            "Actual: Positive\n",
            "Predicted: Positive\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fe9d9645e3c84fd9bef89c5bb8f6f4e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7cb509fbb57c461aae0794aa0cc381e2",
              "IPY_MODEL_d1aa93674acc4a37944b2dc40dc33886",
              "IPY_MODEL_d85e9d9e6b8c41e9a3d41be048f29958"
            ],
            "layout": "IPY_MODEL_66d9fff24e8d4b91b75e7a90d46ef5f5"
          }
        },
        "7cb509fbb57c461aae0794aa0cc381e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b147bff541e746c88179a78e4e94be14",
            "placeholder": "​",
            "style": "IPY_MODEL_bcc24ca6ef454da1be6b7b5a5dd3c251",
            "value": "Downloading data: 100%"
          }
        },
        "d1aa93674acc4a37944b2dc40dc33886": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c33fcbf5952040929ac112b038eff9da",
            "max": 392286,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bf93e419c6bf46529e1c6f44a5e3faf7",
            "value": 392286
          }
        },
        "d85e9d9e6b8c41e9a3d41be048f29958": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4471945c303943149d6c6c602a92cdaa",
            "placeholder": "​",
            "style": "IPY_MODEL_66af35011d85456391d9720f286e0398",
            "value": " 392k/392k [00:00&lt;00:00, 1.48MB/s]"
          }
        },
        "66d9fff24e8d4b91b75e7a90d46ef5f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b147bff541e746c88179a78e4e94be14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bcc24ca6ef454da1be6b7b5a5dd3c251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c33fcbf5952040929ac112b038eff9da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf93e419c6bf46529e1c6f44a5e3faf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4471945c303943149d6c6c602a92cdaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66af35011d85456391d9720f286e0398": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f1904f523444387a92737bde7e88814": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b9dc4ecc9f5430da725a53a820a0fb0",
              "IPY_MODEL_875454d932e44cf5a75de6c33dc3868b",
              "IPY_MODEL_e7a81b2def3f4d80b21f5df4f79b128b"
            ],
            "layout": "IPY_MODEL_a736072ca3b446f082efe6eda9df156b"
          }
        },
        "5b9dc4ecc9f5430da725a53a820a0fb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e48719aba5341218d782c80c88599e2",
            "placeholder": "​",
            "style": "IPY_MODEL_d28029c84f4843fcabcd2d5e49eaed02",
            "value": "Generating train split: 100%"
          }
        },
        "875454d932e44cf5a75de6c33dc3868b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53e09819d70d4d46be96889e5f730545",
            "max": 4846,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1dde7ba19f5f418d96de407350518752",
            "value": 4846
          }
        },
        "e7a81b2def3f4d80b21f5df4f79b128b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55ac2df8333b42aa869de80e47e13879",
            "placeholder": "​",
            "style": "IPY_MODEL_d57f4aaa328645b78c5428a20dd85874",
            "value": " 4846/4846 [00:00&lt;00:00, 157441.94 examples/s]"
          }
        },
        "a736072ca3b446f082efe6eda9df156b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e48719aba5341218d782c80c88599e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d28029c84f4843fcabcd2d5e49eaed02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53e09819d70d4d46be96889e5f730545": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dde7ba19f5f418d96de407350518752": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "55ac2df8333b42aa869de80e47e13879": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d57f4aaa328645b78c5428a20dd85874": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}