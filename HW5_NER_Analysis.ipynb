{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "3ea5fe1496d646babd758ef0855c0aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dac091dab772485dbca46a54f81a9c64",
              "IPY_MODEL_2cb70ae8b0d54feaacfb312f841f75ff",
              "IPY_MODEL_ae0b3d7d6523494db55ee737b525c532"
            ],
            "layout": "IPY_MODEL_2567921d871345438a91607a7e5e1e71"
          }
        },
        "dac091dab772485dbca46a54f81a9c64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5f03ac7cf2ac46da88869d5ede87f949",
            "placeholder": "​",
            "style": "IPY_MODEL_a5013f87165840cba26f7b6cbae78ae7",
            "value": "Downloading data: 100%"
          }
        },
        "2cb70ae8b0d54feaacfb312f841f75ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28f73e3768243d684b55a26336ed5b5",
            "max": 1227788,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95d28ed490064ad5810584261d52fab8",
            "value": 1227788
          }
        },
        "ae0b3d7d6523494db55ee737b525c532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_70c8f0656b5546e999e123c061ca8f04",
            "placeholder": "​",
            "style": "IPY_MODEL_af3ce383ae354d86928ee2ce1a350e2d",
            "value": " 1.23M/1.23M [00:00&lt;00:00, 3.46MB/s]"
          }
        },
        "2567921d871345438a91607a7e5e1e71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f03ac7cf2ac46da88869d5ede87f949": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a5013f87165840cba26f7b6cbae78ae7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f28f73e3768243d684b55a26336ed5b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95d28ed490064ad5810584261d52fab8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "70c8f0656b5546e999e123c061ca8f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af3ce383ae354d86928ee2ce1a350e2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b4337a84c564e4a8f3f6bfb60b21d76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ce5aacfeb4648d6953f45c7bc17731e",
              "IPY_MODEL_3e47e4fd6bc2480cbfc4bb809d65a15f",
              "IPY_MODEL_326c3dfd7c814564a0a114fb6e0425a0"
            ],
            "layout": "IPY_MODEL_801fac3baf7a4e258eff7035e9a5df2c"
          }
        },
        "6ce5aacfeb4648d6953f45c7bc17731e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_21772918fa874d06aebcb0fb50871696",
            "placeholder": "​",
            "style": "IPY_MODEL_aae65dcff7ca413ba2dee1ccca0750a8",
            "value": "Downloading data: 100%"
          }
        },
        "3e47e4fd6bc2480cbfc4bb809d65a15f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_625f98786f4b47529e2131223855a7bd",
            "max": 311883,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_abb703e75b4c4e8884fbdc6757866adb",
            "value": 311883
          }
        },
        "326c3dfd7c814564a0a114fb6e0425a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aacceb8bb8074d9ead6a93b060e24cdb",
            "placeholder": "​",
            "style": "IPY_MODEL_0301a488a7624d01a19aed37f13abb4e",
            "value": " 312k/312k [00:00&lt;00:00, 1.31MB/s]"
          }
        },
        "801fac3baf7a4e258eff7035e9a5df2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21772918fa874d06aebcb0fb50871696": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aae65dcff7ca413ba2dee1ccca0750a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "625f98786f4b47529e2131223855a7bd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "abb703e75b4c4e8884fbdc6757866adb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aacceb8bb8074d9ead6a93b060e24cdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0301a488a7624d01a19aed37f13abb4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e3e8f46e11524f88a04a37a3e1e7e448": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_46162fe1f3174dea8d5c55a92e624919",
              "IPY_MODEL_ed0dc405009e49c1a7fbd48fc740ed52",
              "IPY_MODEL_3b7317f2902c4647873487337eae29c3"
            ],
            "layout": "IPY_MODEL_d57862568d394e0a9f86fa467494ac77"
          }
        },
        "46162fe1f3174dea8d5c55a92e624919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7135edf7e1db44ccabafd0438a178652",
            "placeholder": "​",
            "style": "IPY_MODEL_f208145627494eefa8c4943b40f5ef18",
            "value": "Downloading data: 100%"
          }
        },
        "ed0dc405009e49c1a7fbd48fc740ed52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6ac260c46874ddbbe39bedce3b24931",
            "max": 283307,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6cb089b3f48442aebf3cfb0538a11d28",
            "value": 283307
          }
        },
        "3b7317f2902c4647873487337eae29c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be5e87421e9d4b0a96d2ee746ebc32c4",
            "placeholder": "​",
            "style": "IPY_MODEL_bf1177665cca47bea2b372596c2f0eda",
            "value": " 283k/283k [00:00&lt;00:00, 1.24MB/s]"
          }
        },
        "d57862568d394e0a9f86fa467494ac77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7135edf7e1db44ccabafd0438a178652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f208145627494eefa8c4943b40f5ef18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6ac260c46874ddbbe39bedce3b24931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cb089b3f48442aebf3cfb0538a11d28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be5e87421e9d4b0a96d2ee746ebc32c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf1177665cca47bea2b372596c2f0eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a9cf944853a4f70bcc1392e9659948d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e4d4becad1f74071bb14b182d237a876",
              "IPY_MODEL_c70b366541f943e1b67806e7bf0dae9e",
              "IPY_MODEL_63ad1c11ac32427a921eb12daa8cd2e4"
            ],
            "layout": "IPY_MODEL_a95a068554d54abb954187aeb44bc995"
          }
        },
        "e4d4becad1f74071bb14b182d237a876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7c403d17235e4e01af17ccc0f315e684",
            "placeholder": "​",
            "style": "IPY_MODEL_b1daad20015944099271b48cea4c6bb8",
            "value": "Generating train split: 100%"
          }
        },
        "c70b366541f943e1b67806e7bf0dae9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73758162f00b42ce8c8bd825da146efd",
            "max": 14041,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dafdb689615d4084afcb94629b4cd07d",
            "value": 14041
          }
        },
        "63ad1c11ac32427a921eb12daa8cd2e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2c7265cc02cb4300b5f36e64810b43c5",
            "placeholder": "​",
            "style": "IPY_MODEL_eb62e886b8f2407c91681c38c4fc6232",
            "value": " 14041/14041 [00:00&lt;00:00, 234264.51 examples/s]"
          }
        },
        "a95a068554d54abb954187aeb44bc995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7c403d17235e4e01af17ccc0f315e684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1daad20015944099271b48cea4c6bb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73758162f00b42ce8c8bd825da146efd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dafdb689615d4084afcb94629b4cd07d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2c7265cc02cb4300b5f36e64810b43c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb62e886b8f2407c91681c38c4fc6232": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2cf2a9957d27400aa354675b228bf20d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac19a511bbe74142b5c28fb2777ca987",
              "IPY_MODEL_e3a13ca4ad4448eba137cc9344998e16",
              "IPY_MODEL_0a9b3795508b4b129c93889dc01eb5af"
            ],
            "layout": "IPY_MODEL_5045ec6827894859aa1d5d3d35f6af02"
          }
        },
        "ac19a511bbe74142b5c28fb2777ca987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7a0e2b9b7614c0ba0313a7c40d2574e",
            "placeholder": "​",
            "style": "IPY_MODEL_b4ab31830187483095930d23881a0845",
            "value": "Generating validation split: 100%"
          }
        },
        "e3a13ca4ad4448eba137cc9344998e16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_132f1b719a4c47b5824e1558b9da495f",
            "max": 3250,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7a5383cad004499db325c464f0741ba8",
            "value": 3250
          }
        },
        "0a9b3795508b4b129c93889dc01eb5af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_47eab49319704e719ddcddbdaccd4040",
            "placeholder": "​",
            "style": "IPY_MODEL_609c64f4288c4a5d8aa192cf8333271b",
            "value": " 3250/3250 [00:00&lt;00:00, 114951.20 examples/s]"
          }
        },
        "5045ec6827894859aa1d5d3d35f6af02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7a0e2b9b7614c0ba0313a7c40d2574e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4ab31830187483095930d23881a0845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "132f1b719a4c47b5824e1558b9da495f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a5383cad004499db325c464f0741ba8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "47eab49319704e719ddcddbdaccd4040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "609c64f4288c4a5d8aa192cf8333271b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc2dc622617a46b1a0748bd6cee33146": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cbcecb2b9de34ff29065a074667d260d",
              "IPY_MODEL_5d271bc9efcf42d08aca1f51eeeeaece",
              "IPY_MODEL_1f6dca689a45476bafde4116f72dbe91"
            ],
            "layout": "IPY_MODEL_37e371ee897f47a097af84981cd84560"
          }
        },
        "cbcecb2b9de34ff29065a074667d260d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_555e9c19267f45c6898854b92b99dee3",
            "placeholder": "​",
            "style": "IPY_MODEL_bf922dbcc81b4c10867144f692a5f0d5",
            "value": "Generating test split: 100%"
          }
        },
        "5d271bc9efcf42d08aca1f51eeeeaece": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1cd998fa86b455391d6c7978cde12f6",
            "max": 3453,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2f4fca6bb23042ba98f37675c043a59b",
            "value": 3453
          }
        },
        "1f6dca689a45476bafde4116f72dbe91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8dd2556dffd945848fbe4520c64f2a61",
            "placeholder": "​",
            "style": "IPY_MODEL_09f3eeec49f146599e8668aceaa349f1",
            "value": " 3453/3453 [00:00&lt;00:00, 122144.62 examples/s]"
          }
        },
        "37e371ee897f47a097af84981cd84560": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "555e9c19267f45c6898854b92b99dee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf922dbcc81b4c10867144f692a5f0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1cd998fa86b455391d6c7978cde12f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f4fca6bb23042ba98f37675c043a59b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8dd2556dffd945848fbe4520c64f2a61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09f3eeec49f146599e8668aceaa349f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oB-HQL2YA5mJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be483c35-978b-4050-84b1-5a77c5d2f15d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting datasets\n",
            "  Downloading datasets-2.19.0-py3-none-any.whl (542 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/542.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.4/542.0 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m542.0/542.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.13.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.23.5)\n",
            "Collecting pyarrow>=12.0.0 (from datasets)\n",
            "  Downloading pyarrow-16.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.8/40.8 MB\u001b[0m \u001b[31m33.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Collecting multiprocess (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2024.3.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.9.3)\n",
            "Collecting huggingface-hub>=0.21.2 (from datasets)\n",
            "  Downloading huggingface_hub-0.23.0-py3-none-any.whl (401 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.2/401.2 kB\u001b[0m \u001b[31m55.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.21.2->datasets) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Installing collected packages: pyarrow, dill, multiprocess, huggingface-hub, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 10.0.1\n",
            "    Uninstalling pyarrow-10.0.1:\n",
            "      Successfully uninstalled pyarrow-10.0.1\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.20.3\n",
            "    Uninstalling huggingface-hub-0.20.3:\n",
            "      Successfully uninstalled huggingface-hub-0.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ibis-framework 7.1.0 requires pyarrow<15,>=2, but you have pyarrow 16.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.19.0 dill-0.3.8 huggingface-hub-0.23.0 multiprocess-0.70.16 pyarrow-16.0.0\n",
            "Collecting loralib\n",
            "  Downloading loralib-0.1.2-py3-none-any.whl (10 kB)\n",
            "Installing collected packages: loralib\n",
            "Successfully installed loralib-0.1.2\n",
            "Collecting tiktoken\n",
            "  Downloading tiktoken-0.6.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2024.2.2)\n",
            "Installing collected packages: tiktoken\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed tiktoken-0.6.0\n",
            "Collecting rotary-embedding-torch\n",
            "  Downloading rotary_embedding_torch-0.5.3-py3-none-any.whl (5.3 kB)\n",
            "Collecting beartype (from rotary-embedding-torch)\n",
            "  Downloading beartype-0.18.5-py3-none-any.whl (917 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m917.8/917.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops>=0.7 (from rotary-embedding-torch)\n",
            "  Downloading einops-0.8.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/43.2 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=2.0 in /usr/local/lib/python3.10/dist-packages (from rotary-embedding-torch) (2.1.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0->rotary-embedding-torch) (2.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0->rotary-embedding-torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0->rotary-embedding-torch) (1.3.0)\n",
            "Installing collected packages: einops, beartype, rotary-embedding-torch\n",
            "Successfully installed beartype-0.18.5 einops-0.8.0 rotary-embedding-torch-0.5.3\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install loralib\n",
        "!pip install tiktoken\n",
        "!pip install rotary-embedding-torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "import tiktoken\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from tiktoken import get_encoding\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import math\n",
        "from typing import Tuple\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch import nn\n",
        "import inspect\n",
        "from rotary_embedding_torch import RotaryEmbedding\n",
        "import loralib as lora"
      ],
      "metadata": {
        "id": "1G6djKlIBDiM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tqdm\n",
        "import gc\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "CZ3P8PA7MAzC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = tiktoken.get_encoding('gpt2')\n",
        "vocab_size = enc.n_vocab\n",
        "\n",
        "# hyperparameters\n",
        "batch_size = 32 # how many independent sequences will we process in parallel? #16\n",
        "max_iters = 5000\n",
        "eval_interval = 100\n",
        "learning_rate = 1e-3\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 1024\n",
        "n_head = 8\n",
        "n_layer = 8\n",
        "dropout = 0.0\n",
        "# ------------\n",
        "class ModelConfig:\n",
        "    block_size: int = 1024\n",
        "    vocab_size: int = 50304 # GPT-2 vocab_size of 50257, padded up to nearest multiple of 64 for efficiency\n",
        "    dim: int = 512\n",
        "    n_layers: int = 8\n",
        "    n_heads: int = 8\n",
        "    max_seq_len: int = 512\n",
        "    layer_norm_eps: float = 1e-6\n",
        "    dropout: float = 0.0\n",
        "    hidden_dim: int = None\n",
        "    n_embd: int = 1024\n",
        "    multiple_of: int = 32\n",
        "    rope_dim: int = 64\n",
        "    bias: bool = True\n",
        "    weight_decay = 1e-1\n",
        "    betas = (0.9, 0.99)\n",
        "    lora_rank: int = 4\n",
        "\n",
        "# Root Mean Square Layer Normalization (https://arxiv.org/abs/1910.07467)\n",
        "# borrowed from the official Llama implementation:\n",
        "# https://github.com/facebookresearch/llama/blob/main/llama/model.py\n",
        "class RMSNorm(torch.nn.Module):\n",
        "    def __init__(self, dim: int, eps: float = 1e-6):\n",
        "        \"\"\"\n",
        "        Initialize the RMSNorm normalization layer.\n",
        "\n",
        "        Args:\n",
        "            dim (int): The dimension of the input tensor.\n",
        "            eps (float, optional): A small value added to the denominator for numerical stability. Default is 1e-6.\n",
        "\n",
        "        Attributes:\n",
        "            eps (float): A small value added to the denominator for numerical stability.\n",
        "            weight (nn.Parameter): Learnable scaling parameter.\n",
        "\n",
        "        \"\"\"\n",
        "        super().__init__()\n",
        "        self.eps = eps\n",
        "        self.weight = nn.Parameter(torch.ones(dim))\n",
        "\n",
        "    def _norm(self, x):\n",
        "        \"\"\"\n",
        "        Apply the RMSNorm normalization to the input tensor.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The normalized tensor.\n",
        "\n",
        "        \"\"\"\n",
        "        return x * torch.rsqrt(x.pow(2).mean(-1, keepdim=True) + self.eps)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the RMSNorm layer.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): The input tensor.\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: The output tensor after applying RMSNorm.\n",
        "\n",
        "        \"\"\"\n",
        "        output = self._norm(x.float()).type_as(x)\n",
        "        return output * self.weight\n",
        "\n",
        "class FeedForward(nn.Module):\n",
        "    def __init__(self, dim: int, hidden_dim: int, multiple_of: int, dropout: float):\n",
        "        super().__init__()\n",
        "        if hidden_dim is None:\n",
        "            hidden_dim = 4 * dim\n",
        "            hidden_dim = int(2 * hidden_dim / 3)\n",
        "            hidden_dim = multiple_of * ((hidden_dim + multiple_of - 1) // multiple_of)\n",
        "        self.w1 = nn.Linear(dim, hidden_dim, bias=False)\n",
        "        self.w2 = nn.Linear(hidden_dim, dim, bias=False)\n",
        "        self.w3 = nn.Linear(dim, hidden_dim, bias=False)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def SwiGLU(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        '''\n",
        "        Compute the SwiGLU activation function (see Section 2 in\n",
        "        https://arxiv.org/abs/2204.02311\n",
        "        '''\n",
        "        return F.silu(self.w1(x)) * self.w3(x)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dropout(self.w2(self.SwiGLU(x)))\n",
        "\n",
        "\n",
        "class CausalSelfAttention(nn.Module):\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        assert config.n_embd % config.n_heads == 0\n",
        "        # key, query, value projections for all heads, but in a batch\n",
        "        self.c_attn = nn.Linear(config.n_embd, 3 * config.n_embd, bias=config.bias)\n",
        "        # output projection\n",
        "        self.c_proj = nn.Linear(config.n_embd, config.n_embd, bias=config.bias)\n",
        "        # regularization\n",
        "        self.attn_dropout = nn.Dropout(config.dropout)\n",
        "        self.resid_dropout = nn.Dropout(config.dropout)\n",
        "        self.n_head = config.n_heads\n",
        "        self.n_embd = config.n_embd\n",
        "        self.dropout = config.dropout\n",
        "        self.rotary = RotaryEmbedding(config.rope_dim)\n",
        "        # flash attention make GPU go brrrrr but support is only in PyTorch >= 2.0\n",
        "        self.flash = hasattr(torch.nn.functional, 'scaled_dot_product_attention')\n",
        "        if not self.flash:\n",
        "            print(\"WARNING: using slow attention. Flash Attention requires PyTorch >= 2.0\")\n",
        "            # causal mask to ensure that attention is only applied to the left in the input sequence\n",
        "            self.register_buffer(\"bias\", torch.tril(torch.ones(config.block_size, config.block_size))\n",
        "                                        .view(1, 1, config.block_size, config.block_size))\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, T, C = x.size() # batch size, sequence length, embedding dimensionality (n_embd)\n",
        "\n",
        "        # calculate query, key, values for all heads in batch and move head forward to be the batch dim\n",
        "        q, k, v  = self.c_attn(x).split(self.n_embd, dim=2)\n",
        "        k = k.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        q = q.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "        v = v.view(B, T, self.n_head, C // self.n_head).transpose(1, 2) # (B, nh, T, hs)\n",
        "\n",
        "        # apply RoPE, see https://arxiv.org/abs/2104.09864\n",
        "        k = self.rotary.rotate_queries_or_keys(k)\n",
        "        q = self.rotary.rotate_queries_or_keys(q)\n",
        "\n",
        "\n",
        "        # causal self-attention; Self-attend: (B, nh, T, hs) x (B, nh, hs, T) -> (B, nh, T, T)\n",
        "        if self.flash:\n",
        "            # efficient attention using Flash Attention CUDA kernels\n",
        "            y = torch.nn.functional.scaled_dot_product_attention(q, k, v, attn_mask=None, dropout_p=self.dropout if self.training else 0, is_causal=True)\n",
        "        else:\n",
        "            # manual implementation of attention\n",
        "            att = (q @ k.transpose(-2, -1)) * (1.0 / math.sqrt(k.size(-1)))\n",
        "            att = att.masked_fill(self.bias[:,:,:T,:T] == 0, float('-inf'))\n",
        "            att = F.softmax(att, dim=-1)\n",
        "            att = self.attn_dropout(att)\n",
        "            y = att @ v # (B, nh, T, T) x (B, nh, T, hs) -> (B, nh, T, hs)\n",
        "        y = y.transpose(1, 2).contiguous().view(B, T, C) # re-assemble all head outputs side by side\n",
        "\n",
        "        # output projection\n",
        "        y = self.resid_dropout(self.c_proj(y))\n",
        "        return y\n",
        "\n",
        "\n",
        "class Block(nn.Module):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super().__init__()\n",
        "        self.rn_1 = RMSNorm(config.n_embd, eps=config.layer_norm_eps)\n",
        "        self.attn = CausalSelfAttention(config)\n",
        "        self.rn_2 = RMSNorm(config.n_embd, eps=config.layer_norm_eps)\n",
        "        self.mlp = FeedForward(config.n_embd, config.hidden_dim, config.multiple_of, config.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.rn_1(x))\n",
        "        x = x + self.mlp(self.rn_2(x))\n",
        "        return x\n",
        "\n",
        "class GPT(nn.Module):\n",
        "\n",
        "    def __init__(self, config: ModelConfig):\n",
        "        super().__init__()\n",
        "        assert config.vocab_size is not None\n",
        "        assert config.block_size is not None\n",
        "        self.config = config\n",
        "\n",
        "        self.transformer = nn.ModuleDict(dict(\n",
        "            wte = nn.Embedding(config.vocab_size, config.n_embd),\n",
        "            drop = nn.Dropout(config.dropout),\n",
        "            h = nn.ModuleList([Block(config) for _ in range(config.n_layers)]),\n",
        "            ln_f = RMSNorm(config.n_embd, eps=config.layer_norm_eps)\n",
        "        ))\n",
        "        self.lm_head = nn.Linear(config.n_embd, config.vocab_size, bias=False)\n",
        "        self.transformer.wte.weight = self.lm_head.weight\n",
        "\n",
        "        # init all weights\n",
        "        self.apply(self._init_weights)\n",
        "        # apply special scaled init to the residual projections, per GPT-2 paper\n",
        "        for pn, p in self.named_parameters():\n",
        "            if pn.endswith('c_proj.weight'):\n",
        "                torch.nn.init.normal_(p, mean=0.0, std=0.02/math.sqrt(2 * config.n_layers))\n",
        "\n",
        "    def _init_weights(self, module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "            if module.bias is not None:\n",
        "                torch.nn.init.zeros_(module.bias)\n",
        "        elif isinstance(module, nn.Embedding):\n",
        "            torch.nn.init.normal_(module.weight, mean=0.0, std=0.02)\n",
        "\n",
        "    def forward(self, idx, targets=None):\n",
        "        device = idx.device\n",
        "        b, t = idx.size()\n",
        "        assert t <= self.config.block_size, f\"Cannot forward sequence of length {t}, block size is only {self.config.block_size}\"\n",
        "        pos = torch.arange(0, t, dtype=torch.long, device=device) # shape (t)\n",
        "\n",
        "        # forward the GPT model itself\n",
        "        tok_emb = self.transformer.wte(idx) # token embeddings of shape (b, t, n_embd)\n",
        "        x = self.transformer.drop(tok_emb)\n",
        "        for block in self.transformer.h:\n",
        "            x = block(x)\n",
        "        x = self.transformer.ln_f(x)\n",
        "\n",
        "        if targets is not None:\n",
        "            # if we are given some desired targets also calculate the loss\n",
        "            logits = self.lm_head(x)\n",
        "            loss = F.cross_entropy(logits.view(-1, logits.size(-1)), targets.view(-1), ignore_index=-1)\n",
        "        else:\n",
        "            # inference-time mini-optimization: only forward the lm_head on the very last position\n",
        "            logits = self.lm_head(x[:, [-1], :]) # note: using list [-1] to preserve the time dim\n",
        "            loss = None\n",
        "\n",
        "        return logits, loss\n",
        "\n",
        "    def configure_optimizers(self, weight_decay, learning_rate, betas, device_type):\n",
        "        # start with all of the candidate parameters\n",
        "        param_dict = {pn: p for pn, p in self.named_parameters()}\n",
        "        # filter out those that do not require grad\n",
        "        param_dict = {pn: p for pn, p in param_dict.items() if p.requires_grad}\n",
        "        # create optim groups. Any parameters that is 2D will be weight decayed, otherwise no.\n",
        "        # i.e. all weight tensors in matmuls + embeddings decay, all biases and layernorms don't.\n",
        "        decay_params = [p for n, p in param_dict.items() if p.dim() >= 2]\n",
        "        nodecay_params = [p for n, p in param_dict.items() if p.dim() < 2]\n",
        "        optim_groups = [\n",
        "            {'params': decay_params, 'weight_decay': weight_decay},\n",
        "            {'params': nodecay_params, 'weight_decay': 0.0}\n",
        "        ]\n",
        "        num_decay_params = sum(p.numel() for p in decay_params)\n",
        "        num_nodecay_params = sum(p.numel() for p in nodecay_params)\n",
        "        print(f\"num decayed parameter tensors: {len(decay_params)}, with {num_decay_params:,} parameters\")\n",
        "        print(f\"num non-decayed parameter tensors: {len(nodecay_params)}, with {num_nodecay_params:,} parameters\")\n",
        "        # Create AdamW optimizer and use the fused version if it is available\n",
        "        fused_available = 'fused' in inspect.signature(torch.optim.AdamW).parameters\n",
        "        use_fused = fused_available and device_type == 'cuda'\n",
        "        extra_args = dict(fused=True) if use_fused else dict()\n",
        "        optimizer = torch.optim.AdamW(optim_groups, lr=learning_rate, betas=betas, **extra_args)\n",
        "        print(f\"using fused AdamW: {use_fused}\")\n",
        "\n",
        "        return optimizer\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def generate(self, idx, max_new_tokens, temperature=1.0, top_k=None):\n",
        "        \"\"\"\n",
        "        Take a conditioning sequence of indices idx (LongTensor of shape (b,t)) and complete\n",
        "        the sequence max_new_tokens times, feeding the predictions back into the model each time.\n",
        "        Most likely you'll want to make sure to be in model.eval() mode of operation for this.\n",
        "        \"\"\"\n",
        "        for _ in range(max_new_tokens):\n",
        "            # if the sequence context is growing too long we must crop it at block_size\n",
        "            idx_cond = idx if idx.size(1) <= self.config.block_size else idx[:, -self.config.block_size:]\n",
        "            # forward the model to get the logits for the index in the sequence\n",
        "            logits, _ = self(idx_cond)\n",
        "            # pluck the logits at the final step and scale by desired temperature\n",
        "            logits = logits[:, -1, :] / temperature\n",
        "            # optionally crop the logits to only the top k options\n",
        "            if top_k is not None:\n",
        "                v, _ = torch.topk(logits, min(top_k, logits.size(-1)))\n",
        "                logits[logits < v[:, [-1]]] = -float('Inf')\n",
        "            # apply softmax to convert logits to (normalized) probabilities\n",
        "            probs = F.softmax(logits, dim=-1)\n",
        "            # sample from the distribution\n",
        "            idx_next = torch.multinomial(probs, num_samples=1)\n",
        "            # append sampled index to the running sequence and continue\n",
        "            idx = torch.cat((idx, idx_next), dim=1)\n",
        "\n",
        "        return idx\n",
        "\n",
        "config = ModelConfig()\n",
        "model = GPT(config)\n",
        "m = model.to(device)\n",
        "\n",
        "# print the number of parameters in the model\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# create a PyTorch optimizer\n",
        "#optimizer = torch.optim.AdamW(model.parameters(), lr=learning_rate)\n",
        "optimizer = model.configure_optimizers(weight_decay=1e-1, learning_rate=0.001, betas= (0.9, 0.99), device_type=device)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HQJhedvMGDh",
        "outputId": "97715fd9-5a11-424c-9aa0-79df11816aa4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "152.749312 M parameters\n",
            "num decayed parameter tensors: 41, with 152,698,880 parameters\n",
            "num non-decayed parameter tensors: 33, with 50,176 parameters\n",
            "using fused AdamW: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3X-XeVtlGUyx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint = torch.load(\"/content/checkpoint_iter_3600_3_99_v3.pth\", map_location=device)\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ],
      "metadata": {
        "id": "_2H-0u1RtFFq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1696f10e-6a0f-495d-ed7b-28e9afa357ce"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset\n",
        "## Helper function that aligns encoding between dataset and pretrained model\n",
        "Since the tokenizer we are using differs from the dataset tokenizer. Out tokenizer is more finegrained than the dataset's. Below is what we do to align the two:\n",
        "If a dataset token is split to N tokens by the model tokenizer, then all N tokens will be padded with same NER token of the dataset token. The helper will also return a mask. Only the first of the N tokens are assigned 1 and all other are assined 0. This mask is for testing stage, so that we can align the classifier prediction to the same length of the input dataset token length and calculate F-1 score."
      ],
      "metadata": {
        "id": "DT5ZOZbgMSC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def ner_tokenizer(tokens, tags, enc=enc):\n",
        "    ner_tokens = []\n",
        "    ner_tags = []\n",
        "    ner_mask = []\n",
        "    for i, token in enumerate(tokens):\n",
        "        encoded = enc.encode(token)\n",
        "        ner_tag = [tags[i]] * len(encoded)\n",
        "        mask = [1] + [0] * (len(encoded) - 1)\n",
        "        ner_tokens += encoded\n",
        "        ner_mask += mask\n",
        "        ner_tags += ner_tag\n",
        "    assert len(ner_tokens) == len(ner_mask)\n",
        "    return ner_tokens, ner_tags, ner_mask"
      ],
      "metadata": {
        "id": "5IP5bySVDGjH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j-e75vONFKcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load the dataset\n",
        "https://huggingface.co/datasets/conll2003"
      ],
      "metadata": {
        "id": "4r5KZBuXMeCH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333,
          "referenced_widgets": [
            "3ea5fe1496d646babd758ef0855c0aa1",
            "dac091dab772485dbca46a54f81a9c64",
            "2cb70ae8b0d54feaacfb312f841f75ff",
            "ae0b3d7d6523494db55ee737b525c532",
            "2567921d871345438a91607a7e5e1e71",
            "5f03ac7cf2ac46da88869d5ede87f949",
            "a5013f87165840cba26f7b6cbae78ae7",
            "f28f73e3768243d684b55a26336ed5b5",
            "95d28ed490064ad5810584261d52fab8",
            "70c8f0656b5546e999e123c061ca8f04",
            "af3ce383ae354d86928ee2ce1a350e2d",
            "0b4337a84c564e4a8f3f6bfb60b21d76",
            "6ce5aacfeb4648d6953f45c7bc17731e",
            "3e47e4fd6bc2480cbfc4bb809d65a15f",
            "326c3dfd7c814564a0a114fb6e0425a0",
            "801fac3baf7a4e258eff7035e9a5df2c",
            "21772918fa874d06aebcb0fb50871696",
            "aae65dcff7ca413ba2dee1ccca0750a8",
            "625f98786f4b47529e2131223855a7bd",
            "abb703e75b4c4e8884fbdc6757866adb",
            "aacceb8bb8074d9ead6a93b060e24cdb",
            "0301a488a7624d01a19aed37f13abb4e",
            "e3e8f46e11524f88a04a37a3e1e7e448",
            "46162fe1f3174dea8d5c55a92e624919",
            "ed0dc405009e49c1a7fbd48fc740ed52",
            "3b7317f2902c4647873487337eae29c3",
            "d57862568d394e0a9f86fa467494ac77",
            "7135edf7e1db44ccabafd0438a178652",
            "f208145627494eefa8c4943b40f5ef18",
            "d6ac260c46874ddbbe39bedce3b24931",
            "6cb089b3f48442aebf3cfb0538a11d28",
            "be5e87421e9d4b0a96d2ee746ebc32c4",
            "bf1177665cca47bea2b372596c2f0eda",
            "8a9cf944853a4f70bcc1392e9659948d",
            "e4d4becad1f74071bb14b182d237a876",
            "c70b366541f943e1b67806e7bf0dae9e",
            "63ad1c11ac32427a921eb12daa8cd2e4",
            "a95a068554d54abb954187aeb44bc995",
            "7c403d17235e4e01af17ccc0f315e684",
            "b1daad20015944099271b48cea4c6bb8",
            "73758162f00b42ce8c8bd825da146efd",
            "dafdb689615d4084afcb94629b4cd07d",
            "2c7265cc02cb4300b5f36e64810b43c5",
            "eb62e886b8f2407c91681c38c4fc6232",
            "2cf2a9957d27400aa354675b228bf20d",
            "ac19a511bbe74142b5c28fb2777ca987",
            "e3a13ca4ad4448eba137cc9344998e16",
            "0a9b3795508b4b129c93889dc01eb5af",
            "5045ec6827894859aa1d5d3d35f6af02",
            "d7a0e2b9b7614c0ba0313a7c40d2574e",
            "b4ab31830187483095930d23881a0845",
            "132f1b719a4c47b5824e1558b9da495f",
            "7a5383cad004499db325c464f0741ba8",
            "47eab49319704e719ddcddbdaccd4040",
            "609c64f4288c4a5d8aa192cf8333271b",
            "cc2dc622617a46b1a0748bd6cee33146",
            "cbcecb2b9de34ff29065a074667d260d",
            "5d271bc9efcf42d08aca1f51eeeeaece",
            "1f6dca689a45476bafde4116f72dbe91",
            "37e371ee897f47a097af84981cd84560",
            "555e9c19267f45c6898854b92b99dee3",
            "bf922dbcc81b4c10867144f692a5f0d5",
            "d1cd998fa86b455391d6c7978cde12f6",
            "2f4fca6bb23042ba98f37675c043a59b",
            "8dd2556dffd945848fbe4520c64f2a61",
            "09f3eeec49f146599e8668aceaa349f1"
          ]
        },
        "id": "YSJqQpCCL6jy",
        "outputId": "88ecfa85-e25f-4f7a-da94-fcdbf5f8dcdc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/1.23M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3ea5fe1496d646babd758ef0855c0aa1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/312k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b4337a84c564e4a8f3f6bfb60b21d76"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/283k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e3e8f46e11524f88a04a37a3e1e7e448"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8a9cf944853a4f70bcc1392e9659948d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2cf2a9957d27400aa354675b228bf20d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc2dc622617a46b1a0748bd6cee33146"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NERClassficationDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, encoder, model):\n",
        "        self.dataset = []\n",
        "        self.labels = []\n",
        "        self.encoder = encoder\n",
        "        self.masks = []\n",
        "        self.model = model\n",
        "        self.model.eval()\n",
        "        for entry in tqdm(dataset):\n",
        "            ner_tokens, ner_tags, ner_mask = ner_tokenizer(entry['tokens'], entry['ner_tags'], encoder)\n",
        "            self.dataset.append(ner_tokens)\n",
        "            self.labels.append(ner_tags)\n",
        "            self.masks.append(ner_mask)\n",
        "        self.length = len(self.labels)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, ind):\n",
        "        ner_tokens = self.dataset[ind]\n",
        "        text = torch.tensor(ner_tokens, dtype=torch.long).to(device)\n",
        "        embed = torch.stack([text]).to(device)\n",
        "        with torch.no_grad():\n",
        "            output = torch.squeeze(self.model(embed, embed)[0])\n",
        "            torch.cuda.empty_cache()\n",
        "        label = self.labels[ind]\n",
        "        label = torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "        mask = self.masks[ind]\n",
        "        mask = torch.tensor(mask, dtype=torch.long)\n",
        "\n",
        "        return output, label\n",
        "\n",
        "    def collate_fn(self, batch):\n",
        "        inputs, labels = zip(*batch)\n",
        "        temp = []\n",
        "        for input in inputs:\n",
        "            if input.dim() == 1:\n",
        "                input = input.view(1, -1)\n",
        "            temp.append(input)\n",
        "        inputs = torch.cat(temp)\n",
        "        labels = torch.cat(labels)\n",
        "\n",
        "        return inputs, labels\n",
        "\n",
        "    def get_dataset(self):\n",
        "        return self.dataset\n",
        "\n",
        "    def get_labels(self):\n",
        "        return self.labels\n",
        "\n",
        "    def get_masks(self):\n",
        "        return self.masks\n",
        "\n",
        "train_dataset = NERClassficationDataset(dataset['train'], enc, m)\n",
        "val_dataset = NERClassficationDataset(dataset['validation'], enc, m)\n",
        "\n",
        "sample_sentence, sample_label = train_dataset[0]\n",
        "print(\"Train data sample: \")\n",
        "print(\"Encoded Sentence:\", sample_sentence.shape)\n",
        "print(\"Label:\", sample_label)\n",
        "sample_sentence, sample_label = val_dataset[0]\n",
        "print(\"Val data sample: \")\n",
        "print(\"Encoded Sentence:\", sample_sentence.shape)\n",
        "print(\"Label:\", sample_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rgx3DbUDOXoK",
        "outputId": "67487872-f7d6-4b50-ae8c-aced817769a6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 14041/14041 [00:02<00:00, 6461.70it/s]\n",
            "100%|██████████| 3250/3250 [00:00<00:00, 6649.81it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data sample: \n",
            "Encoded Sentence: torch.Size([13, 50304])\n",
            "Label: tensor([3, 0, 0, 0, 7, 0, 0, 0, 0, 7, 0, 0, 0])\n",
            "Val data sample: \n",
            "Encoded Sentence: torch.Size([24, 50304])\n",
            "Label: tensor([0, 0, 0, 0, 3, 3, 3, 3, 3, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, collate_fn=train_dataset.collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=256, shuffle=True, collate_fn=val_dataset.collate_fn)\n",
        "for batch in tqdm(train_loader):\n",
        "    inputs, labels = batch\n",
        "    print(inputs.shape)\n",
        "    print(labels.shape)\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkON5Hpzbkm4",
        "outputId": "bb7a3302-bfec-4ea2-d0c8-21bd77caab27"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/55 [00:03<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([5413, 50304])\n",
            "torch.Size([5413])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleClassifier(nn.Module):\n",
        "    def __init__(self, input_dim=50304, output_dim=9):\n",
        "        super(SimpleClassifier, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.linear(x)\n",
        "        return x\n",
        "ner_model = SimpleClassifier()\n",
        "ner_model.to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eqM5DcAvjxQ9",
        "outputId": "04374068-5489-4208-a6fa-e6b9baaf0c00"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SimpleClassifier(\n",
              "  (linear): Linear(in_features=50304, out_features=9, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(ner_model.parameters(), lr=5e-5)"
      ],
      "metadata": {
        "id": "5WRlBkRkj5FZ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    ner_model.train()\n",
        "    total_loss = 0\n",
        "    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} Training\", leave=False)\n",
        "\n",
        "    for inputs, labels in train_loader_tqdm:\n",
        "        # inputs = inputs.squeeze(0)\n",
        "        # labels = labels.squeeze(0)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = ner_model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_loader_tqdm.set_postfix({'Train Loss': f'{loss.item():.4f}'})\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    tqdm.write(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}')\n",
        "\n",
        "    ner_model.eval()\n",
        "    total_val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} Validation\", leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader_tqdm:\n",
        "            # inputs = inputs.squeeze(0)\n",
        "            # labels = labels.squeeze(0)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = ner_model(inputs)\n",
        "            # if outputs.dim() == 1:\n",
        "            #     outputs = outputs.view(1, -1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    if epoch == num_epochs - 1:\n",
        "        print()\n",
        "    tqdm.write(f'Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%')\n"
      ],
      "metadata": {
        "id": "yfwzIFxsj93X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# logging\n",
        "import wandb\n",
        "wandb.login(key=\"197d96ebfe1ad37dfd2180d901ca0f779e76bdfe\", relogin=True)\n",
        "# wandb.init(project='HW5', name='NER-fineTune_v2')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXFUgu3MjsYR",
        "outputId": "21cdd1f3-d262-45e9-d472-2fd1c4cface2"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.init(\n",
        "    name    = \"NER-fineTune_v2\", ### Wandb creates random run names if you skip this field, we recommend you give useful names\n",
        "    reinit  = True, ### Allows reinitalizing runs when you re-run this cell\n",
        "    # id     = \"y28t31uh\", ### Insert specific run id here if you want to resume a previous run\n",
        "    #resume = \"must\", ### You need this to resume previous runs, but comment out reinit = True when using this\n",
        "    project = \"HW5\", ### Project should be created in your wandb account\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "6a6TNCFGsPWW",
        "outputId": "3c056337-0742-4648-ee55-184a8ffa94d1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mabasrith\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240502_185715-h7diw84i</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/abasrith/HW5/runs/h7diw84i' target=\"_blank\">NER-fineTune_v2</a></strong> to <a href='https://wandb.ai/abasrith/HW5' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/abasrith/HW5' target=\"_blank\">https://wandb.ai/abasrith/HW5</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/abasrith/HW5/runs/h7diw84i' target=\"_blank\">https://wandb.ai/abasrith/HW5/runs/h7diw84i</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/abasrith/HW5/runs/h7diw84i?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x780de8a37ca0>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "_pN_0vuvdF3l"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(val_loader))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwrCOLKal2Bk",
        "outputId": "1387c8bc-5701-41e2-f1e2-287e1c6e46f4"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 25\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    ner_model.train()\n",
        "    total_loss = 0\n",
        "    train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} Training\", leave=False)\n",
        "\n",
        "    for inputs, labels in train_loader_tqdm:\n",
        "        # inputs = inputs.squeeze(0)\n",
        "        # labels = labels.squeeze(0)\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = ner_model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        train_loader_tqdm.set_postfix({'Train Loss': f'{loss.item():.4f}'})\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "    tqdm.write(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {avg_train_loss:.4f}')\n",
        "    wandb.log({'Epoch': (epoch + 1),'Train Loss': avg_train_loss})\n",
        "\n",
        "    ner_model.eval()\n",
        "    total_val_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    val_loader_tqdm = tqdm(val_loader, desc=f\"Epoch {epoch + 1}/{num_epochs} Validation\", leave=True)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        f1_score_val_total = 0\n",
        "        for inputs, labels in val_loader_tqdm:\n",
        "            # inputs = inputs.squeeze(0)\n",
        "            # labels = labels.squeeze(0)\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = ner_model(inputs)\n",
        "            # if outputs.dim() == 1:\n",
        "            #     outputs = outputs.view(1, -1)\n",
        "            loss = criterion(outputs, labels)\n",
        "            total_val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            labels_list = labels.tolist()\n",
        "            predicted_list = predicted.tolist()\n",
        "            f1_score_val = f1_score(labels_list, predicted_list, average='micro')\n",
        "            f1_score_val_total += f1_score_val\n",
        "            print(f\"F1 score:{f1_score_val}\")\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    f1_score_val_total = f1_score_val_total / len(val_loader)\n",
        "    wandb.log({'F1 score per Epoch':f1_score_val_total})\n",
        "    avg_val_loss = total_val_loss / len(val_loader)\n",
        "    accuracy = 100 * correct / total\n",
        "    tqdm.write(f'Validation Loss: {avg_val_loss:.4f}, Accuracy: {accuracy:.2f}%')\n",
        "    wandb.log({'val_acc': accuracy, 'Val Loss': avg_val_loss})"
      ],
      "metadata": {
        "id": "WGxjhBxjbdSN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f44JVXOfHAD8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save(\n",
        "        {'model_state_dict'         : ner_model.state_dict()},\n",
        "         \"ner_weights.pth\"\n",
        "    )"
      ],
      "metadata": {
        "id": "hGx-2g4kx17G"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = train_dataset = NERClassficationDataset(dataset['test'], enc, m)\n",
        "test_data = test_dataset.get_dataset()\n",
        "test_labels = test_dataset.get_labels()\n",
        "test_mask = test_dataset.get_masks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It-qUEY3MXRM",
        "outputId": "f5b9b747-96e5-429a-bb37-eca72c37a4f9"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3453/3453 [00:00<00:00, 7180.94it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Test output for evaluation\n",
        "Here we use mask to remove padded encodings we added for alignment. If a dataset token is converted to n gpt2 tokens, then the first of the n will be written to the result for evaluation. This ensures the predicted seqence length match the original length."
      ],
      "metadata": {
        "id": "c-9YYQNMSnIc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import inspect\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "\n",
        "def generate(idx, max_new_tokens):\n",
        "    # idx is (B, T) array of indices in the current context\n",
        "    for _ in range(max_new_tokens):\n",
        "        # crop idx to the last block_size tokens\n",
        "        idx_cond = idx[:, -128:]\n",
        "        # get the predictions\n",
        "        logits, loss = ner_model(idx_cond)\n",
        "        # focus only on the last time step\n",
        "        logits = logits[:, -1, :] # becomes (B, C)\n",
        "        # apply softmax to get probabilities\n",
        "        probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "        # sample from the distribution\n",
        "        idx_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "        # append sampled index to the running sequence\n",
        "        idx = torch.cat((idx, idx_next), dim=1) # (B, T+1)\n",
        "    return idx\n"
      ],
      "metadata": {
        "id": "97YGFtOhHx3B"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enc = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "9Wm7dH2RI5DW"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context = torch.zeros((1, 1), dtype=torch.long, device=device)\n",
        "generated_tokens = generate(context, max_new_tokens=2000)[0].tolist()\n",
        "\n",
        "generated_text = enc.decode(generated_tokens)\n",
        "print(f\"Generated text: {generated_text}\")"
      ],
      "metadata": {
        "id": "nApIf3x3HrER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_model.eval()\n",
        "m.eval()\n",
        "res = []\n",
        "for i in tqdm(range(len(test_data))):\n",
        "    text = torch.tensor(test_data[i], dtype=torch.long).to(device)\n",
        "    # print(\"text\",text)\n",
        "    embed = torch.stack([text]).to(device)\n",
        "    with torch.no_grad():\n",
        "        input = torch.squeeze(m(embed, embed)[0])\n",
        "        torch.cuda.empty_cache()\n",
        "    output = ner_model(input)\n",
        "    # print(input)\n",
        "    if output.dim() == 1:\n",
        "        output = output.view(1, -1)\n",
        "    _, predicted = torch.max(output, 1)\n",
        "    # print(predicted)\n",
        "    predicted = predicted.to(device)\n",
        "\n",
        "    res_pred = []\n",
        "    for j in range(len(test_mask[i])):\n",
        "        if test_mask[i][j] == 1:\n",
        "            res_pred.append(int(predicted[j]))\n",
        "    res.append(res_pred)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ktzalYqNqE7",
        "outputId": "7d2dcfb4-c750-4b3d-8742-0a521d336330"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3453/3453 [00:45<00:00, 75.66it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(res)):\n",
        "    assert len(res[i]) == len(dataset['test'][i]['tokens'])"
      ],
      "metadata": {
        "id": "F_bZyaHTRJL1"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "filename = \"output.csv\"\n",
        "with open(filename, mode='w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerows(res)"
      ],
      "metadata": {
        "id": "ZfY_mLwGQjR_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "with open(\"output.csv\", mode='r', newline='') as file:\n",
        "    for line in file:\n",
        "        pred = line.split(',')\n",
        "        pred = [int(s) for s in pred]\n",
        "        preds.append(pred)\n",
        "        full_preds = []\n",
        "        for p in preds:\n",
        "            full_preds += p\n",
        "\n",
        "total = 0\n",
        "for i in range(len(dataset)):\n",
        "    total += f1_score(dataset[i]['ner_tags'], preds[i], average='micro')\n",
        "total / len(dataset)"
      ],
      "metadata": {
        "id": "akw3bFmIPk93"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_preds = []\n",
        "for p in preds:\n",
        "    full_preds += p\n",
        "full_truth = []\n",
        "for data in dataset:\n",
        "    full_truth += data['ner_tags']\n",
        "\n",
        "assert len(full_preds) == len(full_truth)"
      ],
      "metadata": {
        "id": "yCyOYDHlP9XB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, labels in val_loader_tqdm:\n",
        "    # inputs = inputs.squeeze(0)\n",
        "    # labels = labels.squeeze(0)\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    outputs = ner_model(inputs)\n",
        "    # if outputs.dim() == 1:\n",
        "    #     outputs = outputs.view(1, -1)\n",
        "    print(inputs)\n",
        "    # print(\"input\",enc.decode(inputs))\n",
        "    # print(labels)\n",
        "    # print(outputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    total_val_loss += loss.item()\n",
        "    _, predicted = torch.max(outputs, 1)\n",
        "    labels_list = labels.tolist()\n",
        "    predicted_list = predicted.tolist()\n",
        "    f1_score_val = f1_score(labels_list, predicted_list, average='micro')\n",
        "    f1_score_val_total += f1_score_val\n",
        "    # print(f\"F1 score:{f1_score_val}\")\n",
        "    total += labels.size(0)\n",
        "    correct += (predicted == labels).sum().item()"
      ],
      "metadata": {
        "id": "ceW_mvNAB8JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_sample_dataset = load_dataset(\"conll2003\")['test']"
      ],
      "metadata": {
        "id": "3oeniNYJZVmy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = []\n",
        "with open(\"output.csv\", mode='r', newline='') as file:\n",
        "    for line in file:\n",
        "        pred = line.split(',')\n",
        "        pred = [int(s) for s in pred]\n",
        "        preds.append(pred)\n",
        "\n",
        "total = 0\n",
        "for i in range(len(test_sample_dataset)):\n",
        "    total += f1_score(test_sample_dataset[i]['ner_tags'], preds[i], average='micro')\n",
        "f1 = total / len(test_sample_dataset)\n",
        "f1 = format(f1, \".4f\")\n",
        "print(\"Total f1 score:\", f1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "As7NTvi7ZS5e",
        "outputId": "288f35a5-cc95-4b90-9836-aee861279add"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total f1 score: 0.8431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5WsIhMnjbb6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# idx = 3\n",
        "for idx in range(50):\n",
        "  input_tokens = test_sample_dataset[idx]['tokens']\n",
        "  input_tags = test_sample_dataset[idx]['ner_tags']\n",
        "  input_prediction = preds[idx]\n",
        "  print(\"Input tokens:    \", input_tokens)\n",
        "  print(\"Input sentence:  \", ' '.join(input_tokens))\n",
        "  print(\"Actual tags:     \", input_tags)\n",
        "  print(\"Predicted tags:  \", input_prediction)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9lZ7wcU3ZZJp",
        "outputId": "5fada2b7-72a3-4d17-a6cd-76d6eaa9562c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input tokens:     ['SOCCER', '-', 'JAPAN', 'GET', 'LUCKY', 'WIN', ',', 'CHINA', 'IN', 'SURPRISE', 'DEFEAT', '.']\n",
            "Input sentence:   SOCCER - JAPAN GET LUCKY WIN , CHINA IN SURPRISE DEFEAT .\n",
            "Actual tags:      [0, 0, 5, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 1, 0, 0, 0, 0, 0, 5, 0, 0, 0]\n",
            "Input tokens:     ['Nadim', 'Ladki']\n",
            "Input sentence:   Nadim Ladki\n",
            "Actual tags:      [1, 2]\n",
            "Predicted tags:   [5, 2]\n",
            "Input tokens:     ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06']\n",
            "Input sentence:   AL-AIN , United Arab Emirates 1996-12-06\n",
            "Actual tags:      [5, 0, 5, 6, 6, 0]\n",
            "Predicted tags:   [5, 0, 5, 7, 0, 0]\n",
            "Input tokens:     ['Japan', 'began', 'the', 'defence', 'of', 'their', 'Asian', 'Cup', 'title', 'with', 'a', 'lucky', '2-1', 'win', 'against', 'Syria', 'in', 'a', 'Group', 'C', 'championship', 'match', 'on', 'Friday', '.']\n",
            "Input sentence:   Japan began the defence of their Asian Cup title with a lucky 2-1 win against Syria in a Group C championship match on Friday .\n",
            "Actual tags:      [5, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [5, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 3, 8, 5, 0, 0, 0, 0]\n",
            "Input tokens:     ['But', 'China', 'saw', 'their', 'luck', 'desert', 'them', 'in', 'the', 'second', 'match', 'of', 'the', 'group', ',', 'crashing', 'to', 'a', 'surprise', '2-0', 'defeat', 'to', 'newcomers', 'Uzbekistan', '.']\n",
            "Input sentence:   But China saw their luck desert them in the second match of the group , crashing to a surprise 2-0 defeat to newcomers Uzbekistan .\n",
            "Actual tags:      [0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]\n",
            "Predicted tags:   [0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]\n",
            "Input tokens:     ['China', 'controlled', 'most', 'of', 'the', 'match', 'and', 'saw', 'several', 'chances', 'missed', 'until', 'the', '78th', 'minute', 'when', 'Uzbek', 'striker', 'Igor', 'Shkvyrin', 'took', 'advantage', 'of', 'a', 'misdirected', 'defensive', 'header', 'to', 'lob', 'the', 'ball', 'over', 'the', 'advancing', 'Chinese', 'keeper', 'and', 'into', 'an', 'empty', 'net', '.']\n",
            "Input sentence:   China controlled most of the match and saw several chances missed until the 78th minute when Uzbek striker Igor Shkvyrin took advantage of a misdirected defensive header to lob the ball over the advancing Chinese keeper and into an empty net .\n",
            "Actual tags:      [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Oleg', 'Shatskiku', 'made', 'sure', 'of', 'the', 'win', 'in', 'injury', 'time', ',', 'hitting', 'an', 'unstoppable', 'left', 'foot', 'shot', 'from', 'just', 'outside', 'the', 'area', '.']\n",
            "Input sentence:   Oleg Shatskiku made sure of the win in injury time , hitting an unstoppable left foot shot from just outside the area .\n",
            "Actual tags:      [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [1, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['The', 'former', 'Soviet', 'republic', 'was', 'playing', 'in', 'an', 'Asian', 'Cup', 'finals', 'tie', 'for', 'the', 'first', 'time', '.']\n",
            "Input sentence:   The former Soviet republic was playing in an Asian Cup finals tie for the first time .\n",
            "Actual tags:      [0, 0, 7, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 7, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Despite', 'winning', 'the', 'Asian', 'Games', 'title', 'two', 'years', 'ago', ',', 'Uzbekistan', 'are', 'in', 'the', 'finals', 'as', 'outsiders', '.']\n",
            "Input sentence:   Despite winning the Asian Games title two years ago , Uzbekistan are in the finals as outsiders .\n",
            "Actual tags:      [0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 0, 7, 4, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Two', 'goals', 'from', 'defensive', 'errors', 'in', 'the', 'last', 'six', 'minutes', 'allowed', 'Japan', 'to', 'come', 'from', 'behind', 'and', 'collect', 'all', 'three', 'points', 'from', 'their', 'opening', 'meeting', 'against', 'Syria', '.']\n",
            "Input sentence:   Two goals from defensive errors in the last six minutes allowed Japan to come from behind and collect all three points from their opening meeting against Syria .\n",
            "Actual tags:      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0]\n",
            "Input tokens:     ['Takuya', 'Takagi', 'scored', 'the', 'winner', 'in', 'the', '88th', 'minute', ',', 'rising', 'to', 'head', 'a', 'Hiroshige', 'Yanagimoto', 'cross', 'towards', 'the', 'Syrian', 'goal', 'which', 'goalkeeper', 'Salem', 'Bitar', 'appeared', 'to', 'have', 'covered', 'but', 'then', 'allowed', 'to', 'slip', 'into', 'the', 'net', '.']\n",
            "Input sentence:   Takuya Takagi scored the winner in the 88th minute , rising to head a Hiroshige Yanagimoto cross towards the Syrian goal which goalkeeper Salem Bitar appeared to have covered but then allowed to slip into the net .\n",
            "Actual tags:      [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 7, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 7, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['It', 'was', 'the', 'second', 'costly', 'blunder', 'by', 'Syria', 'in', 'four', 'minutes', '.']\n",
            "Input sentence:   It was the second costly blunder by Syria in four minutes .\n",
            "Actual tags:      [0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0]\n",
            "Input tokens:     ['Defender', 'Hassan', 'Abbas', 'rose', 'to', 'intercept', 'a', 'long', 'ball', 'into', 'the', 'area', 'in', 'the', '84th', 'minute', 'but', 'only', 'managed', 'to', 'divert', 'it', 'into', 'the', 'top', 'corner', 'of', 'Bitar', \"'s\", 'goal', '.']\n",
            "Input sentence:   Defender Hassan Abbas rose to intercept a long ball into the area in the 84th minute but only managed to divert it into the top corner of Bitar 's goal .\n",
            "Actual tags:      [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0]\n",
            "Input tokens:     ['Nader', 'Jokhadar', 'had', 'given', 'Syria', 'the', 'lead', 'with', 'a', 'well-struck', 'header', 'in', 'the', 'seventh', 'minute', '.']\n",
            "Input sentence:   Nader Jokhadar had given Syria the lead with a well-struck header in the seventh minute .\n",
            "Actual tags:      [1, 2, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [5, 2, 2, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Japan', 'then', 'laid', 'siege', 'to', 'the', 'Syrian', 'penalty', 'area', 'for', 'most', 'of', 'the', 'game', 'but', 'rarely', 'breached', 'the', 'Syrian', 'defence', '.']\n",
            "Input sentence:   Japan then laid siege to the Syrian penalty area for most of the game but rarely breached the Syrian defence .\n",
            "Actual tags:      [5, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0]\n",
            "Predicted tags:   [5, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 0]\n",
            "Input tokens:     ['Bitar', 'pulled', 'off', 'fine', 'saves', 'whenever', 'they', 'did', '.']\n",
            "Input sentence:   Bitar pulled off fine saves whenever they did .\n",
            "Actual tags:      [1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [3, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Japan', 'coach', 'Shu', 'Kamo', 'said', ':', \"'\", \"'\", 'The', 'Syrian', 'own', 'goal', 'proved', 'lucky', 'for', 'us', '.']\n",
            "Input sentence:   Japan coach Shu Kamo said : ' ' The Syrian own goal proved lucky for us .\n",
            "Actual tags:      [5, 0, 1, 2, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [5, 0, 5, 2, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['The', 'Syrians', 'scored', 'early', 'and', 'then', 'played', 'defensively', 'and', 'adopted', 'long', 'balls', 'which', 'made', 'it', 'hard', 'for', 'us', '.', \"'\"]\n",
            "Input sentence:   The Syrians scored early and then played defensively and adopted long balls which made it hard for us . '\n",
            "Actual tags:      [0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     [\"'\"]\n",
            "Input sentence:   '\n",
            "Actual tags:      [0]\n",
            "Predicted tags:   [0]\n",
            "Input tokens:     ['Japan', ',', 'co-hosts', 'of', 'the', 'World', 'Cup', 'in', '2002', 'and', 'ranked', '20th', 'in', 'the', 'world', 'by', 'FIFA', ',', 'are', 'favourites', 'to', 'regain', 'their', 'title', 'here', '.']\n",
            "Input sentence:   Japan , co-hosts of the World Cup in 2002 and ranked 20th in the world by FIFA , are favourites to regain their title here .\n",
            "Actual tags:      [5, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [5, 0, 0, 0, 0, 7, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Hosts', 'UAE', 'play', 'Kuwait', 'and', 'South', 'Korea', 'take', 'on', 'Indonesia', 'on', 'Saturday', 'in', 'Group', 'A', 'matches', '.']\n",
            "Input sentence:   Hosts UAE play Kuwait and South Korea take on Indonesia on Saturday in Group A matches .\n",
            "Actual tags:      [0, 5, 0, 5, 0, 5, 6, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 3, 0, 4, 0, 3, 6, 0, 0, 0, 0, 0, 0, 3, 3, 0, 0]\n",
            "Input tokens:     ['All', 'four', 'teams', 'are', 'level', 'with', 'one', 'point', 'each', 'from', 'one', 'game', '.']\n",
            "Input sentence:   All four teams are level with one point each from one game .\n",
            "Actual tags:      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['RUGBY', 'UNION', '-', 'CUTTITTA', 'BACK', 'FOR', 'ITALY', 'AFTER', 'A', 'YEAR', '.']\n",
            "Input sentence:   RUGBY UNION - CUTTITTA BACK FOR ITALY AFTER A YEAR .\n",
            "Actual tags:      [3, 4, 0, 1, 0, 0, 5, 0, 0, 0, 0]\n",
            "Predicted tags:   [3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['ROME', '1996-12-06']\n",
            "Input sentence:   ROME 1996-12-06\n",
            "Actual tags:      [5, 0]\n",
            "Predicted tags:   [3, 0]\n",
            "Input tokens:     ['Italy', 'recalled', 'Marcello', 'Cuttitta']\n",
            "Input sentence:   Italy recalled Marcello Cuttitta\n",
            "Actual tags:      [5, 0, 1, 2]\n",
            "Predicted tags:   [5, 0, 5, 2]\n",
            "Input tokens:     ['on', 'Friday', 'for', 'their', 'friendly', 'against', 'Scotland', 'at', 'Murrayfield', 'more', 'than', 'a', 'year', 'after', 'the', '30-year-old', 'wing', 'announced', 'he', 'was', 'retiring', 'following', 'differences', 'over', 'selection', '.']\n",
            "Input sentence:   on Friday for their friendly against Scotland at Murrayfield more than a year after the 30-year-old wing announced he was retiring following differences over selection .\n",
            "Actual tags:      [0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Cuttitta', ',', 'who', 'trainer', 'George', 'Coste', 'said', 'was', 'certain', 'to', 'play', 'on', 'Saturday', 'week', ',', 'was', 'named', 'in', 'a', '21-man', 'squad', 'lacking', 'only', 'two', 'of', 'the', 'team', 'beaten', '54-21', 'by', 'England', 'at', 'Twickenham', 'last', 'month', '.']\n",
            "Input sentence:   Cuttitta , who trainer George Coste said was certain to play on Saturday week , was named in a 21-man squad lacking only two of the team beaten 54-21 by England at Twickenham last month .\n",
            "Actual tags:      [1, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 5, 0, 0, 0]\n",
            "Predicted tags:   [3, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 0, 5, 0, 0, 0]\n",
            "Input tokens:     ['Stefano', 'Bordon', 'is', 'out', 'through', 'illness', 'and', 'Coste', 'said', 'he', 'had', 'dropped', 'back', 'row', 'Corrado', 'Covi', ',', 'who', 'had', 'been', 'recalled', 'for', 'the', 'England', 'game', 'after', 'five', 'years', 'out', 'of', 'the', 'national', 'team', '.']\n",
            "Input sentence:   Stefano Bordon is out through illness and Coste said he had dropped back row Corrado Covi , who had been recalled for the England game after five years out of the national team .\n",
            "Actual tags:      [1, 2, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [1, 2, 0, 0, 0, 0, 0, 4, 0, 0, 0, 0, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Cuttitta', 'announced', 'his', 'retirement', 'after', 'the', '1995', 'World', 'Cup', ',', 'where', 'he', 'took', 'issue', 'with', 'being', 'dropped', 'from', 'the', 'Italy', 'side', 'that', 'faced', 'England', 'in', 'the', 'pool', 'stages', '.']\n",
            "Input sentence:   Cuttitta announced his retirement after the 1995 World Cup , where he took issue with being dropped from the Italy side that faced England in the pool stages .\n",
            "Actual tags:      [1, 0, 0, 0, 0, 0, 7, 8, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [3, 0, 0, 0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 5, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Coste', 'said', 'he', 'had', 'approached', 'the', 'player', 'two', 'months', 'ago', 'about', 'a', 'comeback', '.']\n",
            "Input sentence:   Coste said he had approached the player two months ago about a comeback .\n",
            "Actual tags:      [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['\"', 'He', 'ended', 'the', 'World', 'Cup', 'on', 'the', 'wrong', 'note', ',', '\"', 'Coste', 'said', '.']\n",
            "Input sentence:   \" He ended the World Cup on the wrong note , \" Coste said .\n",
            "Actual tags:      [0, 0, 0, 0, 7, 8, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 0, 8, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "Input tokens:     ['\"', 'I', 'thought', 'it', 'would', 'be', 'useful', 'to', 'have', 'him', 'back', 'and', 'he', 'said', 'he', 'would', 'be', 'available', '.']\n",
            "Input sentence:   \" I thought it would be useful to have him back and he said he would be available .\n",
            "Actual tags:      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['I', 'think', 'now', 'is', 'the', 'right', 'time', 'for', 'him', 'to', 'return', '.', '\"']\n",
            "Input sentence:   I think now is the right time for him to return . \"\n",
            "Actual tags:      [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Squad', ':', 'Javier', 'Pertile', ',', 'Paolo', 'Vaccari', ',', 'Marcello', 'Cuttitta', ',', 'Ivan', 'Francescato', ',', 'Leandro', 'Manteri', ',', 'Diego', 'Dominguez', ',', 'Francesco', 'Mazzariol', ',', 'Alessandro', 'Troncon', ',', 'Orazio', 'Arancio', ',', 'Andrea', 'Sgorlon', ',', 'Massimo', 'Giovanelli', ',', 'Carlo', 'Checchinato', ',', 'Walter', 'Cristofoletto', ',', 'Franco', 'Properzi', 'Curti', ',', 'Carlo', 'Orlandi', ',', 'Massimo', 'Cuttitta', ',', 'Giambatista', 'Croci', ',', 'Gianluca', 'Guidi', ',', 'Nicola', 'Mazzucato', ',', 'Alessandro', 'Moscardi', ',', 'Andrea', 'Castellani', '.']\n",
            "Input sentence:   Squad : Javier Pertile , Paolo Vaccari , Marcello Cuttitta , Ivan Francescato , Leandro Manteri , Diego Dominguez , Francesco Mazzariol , Alessandro Troncon , Orazio Arancio , Andrea Sgorlon , Massimo Giovanelli , Carlo Checchinato , Walter Cristofoletto , Franco Properzi Curti , Carlo Orlandi , Massimo Cuttitta , Giambatista Croci , Gianluca Guidi , Nicola Mazzucato , Alessandro Moscardi , Andrea Castellani .\n",
            "Actual tags:      [0, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0]\n",
            "Predicted tags:   [3, 0, 1, 2, 0, 5, 2, 0, 1, 1, 0, 1, 2, 0, 1, 2, 0, 1, 1, 0, 0, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 4, 2, 0, 5, 2, 0, 1, 5, 0, 1, 2, 2, 0, 0, 2, 0, 1, 1, 0, 5, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0]\n",
            "Input tokens:     ['SOCCER', '-', 'LATE', 'GOALS', 'GIVE', 'JAPAN', 'WIN', 'OVER', 'SYRIA', '.']\n",
            "Input sentence:   SOCCER - LATE GOALS GIVE JAPAN WIN OVER SYRIA .\n",
            "Actual tags:      [0, 0, 0, 0, 0, 5, 0, 0, 5, 0]\n",
            "Predicted tags:   [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['AL-AIN', ',', 'United', 'Arab', 'Emirates', '1996-12-06']\n",
            "Input sentence:   AL-AIN , United Arab Emirates 1996-12-06\n",
            "Actual tags:      [5, 0, 5, 6, 6, 0]\n",
            "Predicted tags:   [5, 0, 5, 7, 0, 0]\n",
            "Input tokens:     ['Two', 'goals', 'in', 'the', 'last', 'six', 'minutes', 'gave', 'holders', 'Japan', 'an', 'uninspiring', '2-1', 'Asian', 'Cup', 'victory', 'over', 'Syria', 'on', 'Friday', '.']\n",
            "Input sentence:   Two goals in the last six minutes gave holders Japan an uninspiring 2-1 Asian Cup victory over Syria on Friday .\n",
            "Actual tags:      [0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 7, 8, 0, 0, 5, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7, 7, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Takuya', 'Takagi', 'headed', 'the', 'winner', 'in', 'the', '88th', 'minute', 'of', 'the', 'group', 'C', 'game', 'after', 'goalkeeper', 'Salem', 'Bitar', 'spoiled', 'a', 'mistake-free', 'display', 'by', 'allowing', 'the', 'ball', 'to', 'slip', 'under', 'his', 'body', '.']\n",
            "Input sentence:   Takuya Takagi headed the winner in the 88th minute of the group C game after goalkeeper Salem Bitar spoiled a mistake-free display by allowing the ball to slip under his body .\n",
            "Actual tags:      [1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['It', 'was', 'the', 'second', 'Syrian', 'defensive', 'blunder', 'in', 'four', 'minutes', '.']\n",
            "Input sentence:   It was the second Syrian defensive blunder in four minutes .\n",
            "Actual tags:      [0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Defender', 'Hassan', 'Abbas', 'rose', 'to', 'intercept', 'a', 'long', 'ball', 'into', 'the', 'area', 'in', 'the', '84th', 'minute', 'but', 'only', 'managed', 'to', 'divert', 'it', 'into', 'the', 'top', 'corner', 'of', 'Bitar', \"'s\", 'goal', '.']\n",
            "Input sentence:   Defender Hassan Abbas rose to intercept a long ball into the area in the 84th minute but only managed to divert it into the top corner of Bitar 's goal .\n",
            "Actual tags:      [0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 1, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0]\n",
            "Input tokens:     ['Syria', 'had', 'taken', 'the', 'lead', 'from', 'their', 'first', 'serious', 'attack', 'in', 'the', 'seventh', 'minute', '.']\n",
            "Input sentence:   Syria had taken the lead from their first serious attack in the seventh minute .\n",
            "Actual tags:      [5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Nader', 'Jokhadar', 'headed', 'a', 'cross', 'from', 'the', 'right', 'by', 'Ammar', 'Awad', 'into', 'the', 'top', 'right', 'corner', 'of', 'Kenichi', 'Shimokawa', \"'s\", 'goal', '.']\n",
            "Input sentence:   Nader Jokhadar headed a cross from the right by Ammar Awad into the top right corner of Kenichi Shimokawa 's goal .\n",
            "Actual tags:      [1, 2, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0]\n",
            "Predicted tags:   [5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0]\n",
            "Input tokens:     ['Japan', 'then', 'laid', 'siege', 'to', 'the', 'Syrian', 'penalty', 'area', 'and', 'had', 'a', 'goal', 'disallowed', 'for', 'offside', 'in', 'the', '16th', 'minute', '.']\n",
            "Input sentence:   Japan then laid siege to the Syrian penalty area and had a goal disallowed for offside in the 16th minute .\n",
            "Actual tags:      [5, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [5, 0, 0, 0, 0, 0, 7, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['A', 'minute', 'later', ',', 'Bitar', 'produced', 'a', 'good', 'double', 'save', ',', 'first', 'from', 'Kazuyoshi', 'Miura', \"'s\", 'header', 'and', 'then', 'blocked', 'a', 'Takagi', 'follow-up', 'shot', '.']\n",
            "Input sentence:   A minute later , Bitar produced a good double save , first from Kazuyoshi Miura 's header and then blocked a Takagi follow-up shot .\n",
            "Actual tags:      [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 5, 2, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "Input tokens:     ['Bitar', 'saved', 'well', 'again', 'from', 'Miura', 'in', 'the', '37th', 'minute', ',', 'parrying', 'away', 'his', 'header', 'from', 'a', 'corner', '.']\n",
            "Input sentence:   Bitar saved well again from Miura in the 37th minute , parrying away his header from a corner .\n",
            "Actual tags:      [1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [3, 7, 0, 0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Japan', 'started', 'the', 'second', 'half', 'brightly', 'but', 'Bitar', 'denied', 'them', 'an', 'equaliser', 'when', 'he', 'dived', 'to', 'his', 'right', 'to', 'save', 'Naoki', 'Soma', \"'s\", 'low', 'drive', 'in', 'the', '53rd', 'minute', '.']\n",
            "Input sentence:   Japan started the second half brightly but Bitar denied them an equaliser when he dived to his right to save Naoki Soma 's low drive in the 53rd minute .\n",
            "Actual tags:      [5, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Predicted tags:   [5, 0, 0, 0, 0, 0, 0, 7, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "Input tokens:     ['Japan', ':', '19', '-', 'Kenichi', 'Shimokawa', ',', '2', '-', 'Hiroshige', 'Yanagimoto', ',', '3', '-', 'Naoki', 'Soma', ',', '4', '-', 'Masami', 'Ihara', ',', '5', '-', 'Norio', 'Omura', ',', '6', '-', 'Motohiro', 'Yamaguchi', ',', '8', '-', 'Masakiyo', 'Maezono', '(', '7', '-', 'Yasuto', 'Honda', '71', ')', ',', '9', '-', 'Takuya', 'Takagi', ',', '10', '-', 'Hiroshi', 'Nanami', ',', '11', '-', 'Kazuyoshi', 'Miura', ',', '15', '-', 'Hiroaki', 'Morishima', '(', '14', '-', 'Masayuki', 'Okano', '75', ')', '.']\n",
            "Input sentence:   Japan : 19 - Kenichi Shimokawa , 2 - Hiroshige Yanagimoto , 3 - Naoki Soma , 4 - Masami Ihara , 5 - Norio Omura , 6 - Motohiro Yamaguchi , 8 - Masakiyo Maezono ( 7 - Yasuto Honda 71 ) , 9 - Takuya Takagi , 10 - Hiroshi Nanami , 11 - Kazuyoshi Miura , 15 - Hiroaki Morishima ( 14 - Masayuki Okano 75 ) .\n",
            "Actual tags:      [5, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0]\n",
            "Predicted tags:   [5, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 1, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 7, 2, 0, 0, 0, 1, 2, 0, 0, 0]\n",
            "Input tokens:     ['Syria', ':', '24', '-', 'Salem', 'Bitar', ',', '3', '-', 'Bachar', 'Srour', ';', '4', '-', 'Hassan', 'Abbas', ',', '5', '-', 'Tarek', 'Jabban', ',', '6', '-', 'Ammar', 'Awad', '(', '9', '-', 'Louay', 'Taleb', '69', ')', ',', '8', '-', 'Nihad', 'al-Boushi', ',', '10', '-', 'Mohammed', 'Afash', ',', '12', '-', 'Ali', 'Dib', ',', '13', '-', 'Abdul', 'Latif', 'Helou', '(', '17', '-', 'Ammar', 'Rihawiy', '46', ')', ',', '14', '-', 'Khaled', 'Zaher', ';', '16', '-', 'Nader', 'Jokhadar', '.']\n",
            "Input sentence:   Syria : 24 - Salem Bitar , 3 - Bachar Srour ; 4 - Hassan Abbas , 5 - Tarek Jabban , 6 - Ammar Awad ( 9 - Louay Taleb 69 ) , 8 - Nihad al-Boushi , 10 - Mohammed Afash , 12 - Ali Dib , 13 - Abdul Latif Helou ( 17 - Ammar Rihawiy 46 ) , 14 - Khaled Zaher ; 16 - Nader Jokhadar .\n",
            "Actual tags:      [5, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0]\n",
            "Predicted tags:   [0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 0, 0, 0, 1, 2, 2, 0, 0, 0, 1, 5, 0, 0, 0, 0, 0, 1, 2, 0, 0, 0, 1, 1, 0]\n",
            "Input tokens:     ['FREESTYLE', 'SKIING-WORLD', 'CUP', 'MOGUL', 'RESULTS', '.']\n",
            "Input sentence:   FREESTYLE SKIING-WORLD CUP MOGUL RESULTS .\n",
            "Actual tags:      [0, 7, 8, 0, 0, 0]\n",
            "Predicted tags:   [3, 5, 0, 0, 0, 0]\n",
            "Input tokens:     ['TIGNES', ',', 'France', '1996-12-06']\n",
            "Input sentence:   TIGNES , France 1996-12-06\n",
            "Actual tags:      [5, 0, 5, 0]\n",
            "Predicted tags:   [3, 0, 5, 0]\n"
          ]
        }
      ]
    }
  ]
}